{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pypdf import PdfMerger\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from scipy.stats import linregress\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "# import statsmodels.api as sm\n",
    "from scipy.optimize import curve_fit\n",
    "# import subprocess\n",
    "# import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "# to upgrade pandas:\n",
    "# /opt/homebrew/bin/python3.10 -m pip install --upgrade SciencePlots   \n",
    "# pip install SciencePlots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 24 new presets\n",
    "\n",
    "mass_nucleon = 0.938273\n",
    "mass_C12=11.178\n",
    "alpha_fine = 1/137\n",
    "initial_correction = 1.0\n",
    "\n",
    "def round_sig_3(x):\n",
    "    return '%s' % float('%.3g' % x)\n",
    "\n",
    "qvcenters = [0.100, 0.148, 0.167, 0.205, 0.240, 0.300, 0.380, 0.475, 0.570, 0.649, 0.756, 0.991, 1.302, 1.619, 1.921, 2.213, 2.500, 2.783]\n",
    "qvbins = [0.063, 0.124, 0.158, 0.186, 0.223, 0.270, 0.340, 0.428, 0.523, 0.609, 0.702, 0.878, 1.168, 1.460, 1.770, 2.067, 2.357, 2.642, 2.923]\n",
    "qvbin_names = ['0.063~0.124','0.124~0.158','0.158~0.186','0.186~0.223','0.223~0.270','0.270~0.340','0.340~0.428','0.428~0.523','0.523~0.609',\n",
    "               '0.609~0.702','0.702~0.878','0.878~1.168','1.168~1.460','1.460~1.770','1.770~2.067','2.067~2.357','2.357~2.642','2.642~2.923']\n",
    "\n",
    "Q2centers = [0.010, 0.020, 0.026, 0.040, 0.056, 0.093, 0.120, 0.160, 0.265, 0.380, 0.500, 0.800, 1.250, 1.750, 2.250, 2.750, 3.250, 3.750]\n",
    "Q2bins = [0.004, 0.015, 0.025, 0.035, 0.045, 0.070, 0.100, 0.145, 0.206, 0.322, 0.438, 0.650, 1.050, 1.500, 2.000, 2.500, 3.000, 3.500, 4.000]\n",
    "Q2bin_names = ['0.004~0.015','0.015~0.025','0.025~0.035','0.035~0.045','0.045~0.070','0.070~0.100','0.100~0.145','0.145~0.206','0.206~0.322',\n",
    "               '0.322~0.438','0.438~0.650','0.650~1.050','1.050~1.500','1.500~2.000','2.000~2.500','2.500~3.000','3.000~3.500','3.500~4.000']\n",
    "\n",
    "nuwidths = [0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.005, 0.005, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02,0.04, 0.04, 0.04, 0.04, 0.04]\n",
    "nuwidths = [0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.01, 0.01, 0.01, 0.01, 0.01,0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "\n",
    "W2widths = [0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.02,0.02,0.02,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04,0.04]\n",
    "\n",
    "dataSet_to_name = {1:\"Barreau:1983ht\", 2:\"O'Connell:198\", 3:\"Sealock:1989nx\", 4:\"Baran:1988tw\", 5:\"Bagdasaryan:1988hp\", 6:\"Dai - HallA:2019da\", \n",
    "    7:\"Arrington:1995hs\", 8:\"Day:1993md\", 9:\"Arrington:1998psnoCC\", 10:\"Gaskell:2008\", 11:\"Whitney:1974hr\", 12:\"AlsamiJan05\", 13:\"VaheJun07\", \n",
    "    14:\"Gomez74\", 15:\"Fomin\", 16:\"Yamaguchi73\", 17:\"Ryan84\", 18:\"Cyzyk:1963zz\", 19:\"Bounin63\", 20:\"Photo-Daphne\", 21:\"Spamer70\", 22:\"Goldemberg64\", \n",
    "    23:\"DeForrest65\", 24:\"Donnelly68\"}\n",
    "\n",
    "dataSet_to_normError = {1:0.24320E-02, 2:0.86008E-02, 3:0.48305E-02, 4:0.45501E-02, 5:0.82797E-02, 6:0.52969E-02, 7:0.13229E-01, 8:0.33307E-02, \n",
    "        9:0.34432E-02, 10:0.50742E-02, 11:0.15258E-01, 12:0.67079E-03, 13:0.69905E-03, 14:0.14875E-01, 15:0.30856E-02, 16:0.29024E-02, \n",
    "        17:0.13049E-01, 18:0.1, 19:0.23, 20:0.10513, 21:0.4, 22:0.1, 23:0.1}\n",
    "\n",
    "dataSet_to_normalization = {1:0.99185, 2:0.97869, 3:1.0315, 4:0.99241, 5:0.98777, 6:1.0108, 7:0.97427, 8:1.0071, 9:0.98884, 10:0.99340, 11:1.0149, \n",
    "                12:0.99812, 13:1.0029, 14:1.0125, 15:1.0046, 16:1.0019, 17:1.0517, 18:1.0, 19:1.1500, 20:0.99754, 21:1.2, 22:1.1, 23:0.85}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  (archived) Feb 19 bins and presets\n",
    "\n",
    "# # mass_nucleon = (0.938272+0.9406)/2\n",
    "# mass_nucleon = 0.938273\n",
    "# mass_C12=11.178\n",
    "# alpha_fine = 1/137\n",
    "# initial_correction = 1.0\n",
    "\n",
    "# def round_sig_3(x):\n",
    "#     return '%s' % float('%.3g' % x)\n",
    "# # nuwidths = [\n",
    "# #     0.0005, 0.0005, 0.0005, 0.005, 0.005,\n",
    "# #     0.005,   0.005,   0.005,   0.005,  0.01, \n",
    "# #     0.01,     0.01,   0.01,  0.01, 0.01,\n",
    "# #     0.01,     0.01,   0.01,  0.01, 0.01\n",
    "# # ]\n",
    "# nuwidths = [\n",
    "#     0.0005, 0.0005, 0.0005, 0.0005, 0.0005, \n",
    "#     0.005, 0.005, 0.005, 0.005, 0.005,\n",
    "#     0.01, 0.01, 0.01, 0.01, 0.01,\n",
    "#     0.01, 0.01, 0.01, 0.01, 0.01\n",
    "# ]\n",
    "\n",
    "# dataSet_to_normError = {\n",
    "#     1:0.24320E-02,\n",
    "#     2:0.86008E-02,\n",
    "#     3:0.48305E-02,\n",
    "#     4:0.45501E-02,\n",
    "#     5:0.82797E-02,\n",
    "#     6:0.52969E-02,\n",
    "#     7:0.13229E-01,\n",
    "#     8:0.33307E-02,\n",
    "#     9:0.34432E-02,\n",
    "#     10:0.50742E-02,\n",
    "#     11:0.15258E-01,\n",
    "#     12:0.67079E-03,\n",
    "#     13:0.69905E-03,\n",
    "#     14:0.14875E-01,\n",
    "#     15:0.30856E-02,\n",
    "#     16:0.29024E-02,\n",
    "#     17:0.13049E-01,\n",
    "#     18:0.1,\n",
    "#     # 18:1.0,\n",
    "\n",
    "#     # 19:0.2,\n",
    "#     19:0.23,\n",
    "#     20:0.10513,\n",
    "#     # 21:0.1,\n",
    "#     21:0.1,\n",
    "#     22:0.1,\n",
    "#     23:0.1\n",
    "# }\n",
    "\n",
    "# dataSet_to_normalization = {\n",
    "#     1:0.99185,\n",
    "#     2:0.97869,    \n",
    "#     3:1.0315,     \n",
    "#     4:0.99241,    \n",
    "#     5:0.98777,    \n",
    "#     6:1.0108,     \n",
    "#     7:0.97427,    \n",
    "#     8:1.0071,       \n",
    "#     9:0.98884,    \n",
    "#     10:0.99340,    \n",
    "#     11:1.0149,    \n",
    "#     12:0.99812,   \n",
    "#     13:1.0029,    \n",
    "#     14:1.0125,       \n",
    "#     15:1.0046,      \n",
    "#     16:1.0019,    \n",
    "#     17:1.0517,  \n",
    "#     # 18:1.1000,\n",
    "#     18:1.0,\n",
    "\n",
    "#     19:1.1500, \n",
    "#     20:0.99754,\n",
    "#     21:1.2,\n",
    "#     22:1.1,\n",
    "#     23:0.85\n",
    "# }\n",
    "\n",
    "\n",
    "# dataSet_to_name = {\n",
    "#     1:\"Barreau:1983ht\",\n",
    "#     2:\"O'Connell:1987ag\",\n",
    "#     3:\"Sealock:1989nx\",\n",
    "#     4:\"Baran:1988tw\",\n",
    "#     5:\"Bagdasaryan:1988hp\",\n",
    "#     6:\"Dai - HallA:2019da\",\n",
    "#     7:\"Arrington:1995hs\",\n",
    "#     8:\"Day:1993md\",\n",
    "#     9:\"Arrington:1998psnoCC\",\n",
    "#     10:\"Gaskell:2008\",\n",
    "#     11:\"Whitney:1974hr\",\n",
    "#     12:\"AlsamiJan05\",\n",
    "#     13:\"VaheJun07\",\n",
    "#     14:\"Gomez74\",\n",
    "#     15:\"Fomin\",\n",
    "#     16:\"Yamaguchi73\",\n",
    "#     17:\"Ryan84\",\n",
    "#     18:\"Cyzyk:1963zz\",\n",
    "#     19:\"Bounin63\",\n",
    "#     20:\"Photo-Daphne\",\n",
    "#     21:\"Spamer70\",\n",
    "#     22:\"Goldemberg64\",\n",
    "#     23:\"DeForrest65\",\n",
    "#     24:\"Donnelly68\"\n",
    "# }\n",
    "\n",
    "# qvbins = [\n",
    "#     0.063,\n",
    "#     0.124,\n",
    "#     0.158,\n",
    "#     0.186,\n",
    "#     0.223,\n",
    "#     0.270,\n",
    "#     0.340,\n",
    "#     0.428,\n",
    "#     0.523,\n",
    "#     0.609,\n",
    "#     0.702,\n",
    "#     0.817,\n",
    "#     0.934,\n",
    "#     1.079,\n",
    "#     1.227,\n",
    "#     1.460,\n",
    "#     1.770,\n",
    "#     2.067,\n",
    "#     2.357,\n",
    "#     2.642,\n",
    "#     2.932\n",
    "# ]\n",
    "\n",
    "# qvbin_names = [\n",
    "#     '0.063~0.124',\n",
    "#     '0.124~0.158',\n",
    "#     '0.158~0.186',\n",
    "#     '0.186~0.223',\n",
    "#     '0.223~0.270',\n",
    "#     '0.270~0.340',\n",
    "#     '0.340~0.428',\n",
    "#     '0.428~0.523',\n",
    "#     '0.523~0.609',\n",
    "#     '0.609~0.702',\n",
    "#     '0.702~0.817',\n",
    "#     '0.817~0.934',\n",
    "#     '0.934~1.079',\n",
    "#     '1.079~1.227',\n",
    "#     '1.227~1.460',\n",
    "#     '1.460~1.770',\n",
    "#     '1.770~2.067',\n",
    "#     '2.067~2.357',\n",
    "#     '2.357~2.642',\n",
    "#     '2.642~2.932'\n",
    "# ]\n",
    "\n",
    "# qvcenters = [\n",
    "#     0.100,\n",
    "#     0.148,\n",
    "#     0.167,\n",
    "#     0.205,\n",
    "#     0.240,\n",
    "#     0.300,\n",
    "#     0.380,\n",
    "#     0.475,\n",
    "#     0.570,\n",
    "#     0.649,\n",
    "#     0.756,\n",
    "#     0.878,\n",
    "#     0.991,\n",
    "#     1.168,\n",
    "#     1.302,\n",
    "#     1.619,\n",
    "#     1.921,\n",
    "#     2.213,\n",
    "#     2.500,\n",
    "#     2.783\n",
    "# ]\n",
    "\n",
    "# qvbin_name_to_qvcenter = {\n",
    "#     '0.063~0.124':0.100,\n",
    "#     '0.124~0.158':0.148,\n",
    "#     '0.158~0.186':0.167,\n",
    "#     '0.186~0.223':0.205,\n",
    "#     '0.223~0.270':0.240,\n",
    "#     '0.270~0.340':0.300,\n",
    "#     '0.340~0.428':0.380,\n",
    "#     '0.428~0.523':0.475,\n",
    "#     '0.523~0.609':0.570,\n",
    "#     '0.609~0.702':0.649,\n",
    "#     '0.702~0.817':0.756,\n",
    "#     '0.817~0.934':0.878,\n",
    "#     '0.934~1.079':0.991,\n",
    "#     '1.079~1.227':1.168,\n",
    "#     '1.227~1.460':1.302,\n",
    "#     '1.460~1.770':1.619,\n",
    "#     '1.770~2.067':1.921,\n",
    "#     '2.067~2.357':2.213,\n",
    "#     '2.357~2.642':2.500,\n",
    "#     '2.642~2.932':2.783\n",
    "    \n",
    "# }\n",
    "\n",
    "# W2widths = [\n",
    "#     0.01,\n",
    "#     0.01,\n",
    "#     0.01,\n",
    "#     0.01,\n",
    "#     0.01,\n",
    "#     0.01,\n",
    "#     0.01,\n",
    "#     0.01,\n",
    "#     0.02,\n",
    "#     0.02,\n",
    "#     0.02,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "#     0.04,\n",
    "# ]\n",
    "\n",
    "# bins = [\n",
    "#     0.004,\n",
    "#     0.015,\n",
    "#     0.025,\n",
    "#     0.035,\n",
    "#     0.045,\n",
    "#     0.070,\n",
    "#     0.100,\n",
    "#     0.145,\n",
    "#     0.209,\n",
    "#     0.322,\n",
    "#     0.438,\n",
    "#     0.562,\n",
    "#     0.738,\n",
    "#     0.962,\n",
    "#     1.150,\n",
    "#     1.500,\n",
    "#     2.000,\n",
    "#     2.500,\n",
    "#     3.000,\n",
    "#     3.500,\n",
    "#     4.000\n",
    "# ]\n",
    "\n",
    "# Q2bin_names=[\n",
    "#     \"0.004~0.015\",\n",
    "#     \"0.015~0.025\",\n",
    "#     \"0.025~0.035\",\n",
    "#     \"0.035~0.045\",\n",
    "#     \"0.045~0.070\",\n",
    "#     \"0.070~0.100\",\n",
    "#     \"0.100~0.145\",\n",
    "#     \"0.145~0.209\",\n",
    "#     \"0.209~0.322\",\n",
    "#     \"0.322~0.438\",\n",
    "#     \"0.438~0.562\",\n",
    "#     \"0.562~0.738\",\n",
    "#     \"0.738~0.962\",\n",
    "#     \"0.962~1.150\",\n",
    "#     \"1.150~1.500\",\n",
    "#     \"1.500~2.000\",\n",
    "#     \"2.000~2.500\",\n",
    "#     \"2.500~3.000\",\n",
    "#     \"3.000~3.500\",\n",
    "#     \"3.500~4.000\"\n",
    "#     ]\n",
    "\n",
    "# Q2bin_to_W2width={\n",
    "#     \"0.004~0.015\":0.01,\n",
    "#     \"0.015~0.025\":0.01,\n",
    "#     \"0.025~0.035\":0.01,\n",
    "#     \"0.035~0.045\":0.01,\n",
    "#     \"0.045~0.070\":0.01,\n",
    "#     \"0.070~0.100\":0.01,\n",
    "#     \"0.100~0.145\":0.01,\n",
    "#     \"0.145~0.209\":0.02,\n",
    "#     \"0.209~0.322\":0.02,\n",
    "#     \"0.322~0.438\":0.02,\n",
    "#     \"0.438~0.562\":0.04,\n",
    "#     \"0.562~0.738\":0.04,\n",
    "#     \"0.738~0.962\":0.04,\n",
    "#     \"0.962~1.138\":0.04\n",
    "# }\n",
    "\n",
    "# Q2centers = [\n",
    "#     0.010,\n",
    "#     0.020,\n",
    "#     0.026,\n",
    "#     0.040,\n",
    "#     0.056,\n",
    "#     0.093,\n",
    "#     0.120,\n",
    "#     0.160,\n",
    "#     0.265,\n",
    "#     0.380,\n",
    "#     0.500,\n",
    "#     0.650,\n",
    "#     0.800,\n",
    "#     1.050,\n",
    "#     1.250,\n",
    "#     1.750,\n",
    "#     2.250,\n",
    "#     2.750,\n",
    "#     3.250,\n",
    "#     3.750\n",
    "# ]\n",
    "\n",
    "# Q2bin_to_Q2center = {\n",
    "#     \"0.004~0.015\":0.010,\n",
    "#     \"0.015~0.025\":0.020,\n",
    "#     \"0.025~0.035\":0.026,\n",
    "#     \"0.035~0.045\":0.040,\n",
    "#     \"0.045~0.070\":0.056,\n",
    "#     \"0.070~0.100\":0.093,\n",
    "#     \"0.100~0.145\":0.120,\n",
    "#     \"0.145~0.209\":0.160,\n",
    "#     \"0.209~0.322\":0.265,\n",
    "#     \"0.322~0.438\":0.380,\n",
    "#     \"0.438~0.562\":0.500,\n",
    "#     \"0.562~0.738\":0.650,\n",
    "#     \"0.738~0.962\":0.800,\n",
    "#     \"0.962~1.150\":1.050,\n",
    "#     \"1.150~1.500\":1.250,\n",
    "#     \"1.500~2.000\":1.750,\n",
    "#     \"2.000~2.500\":2.250,\n",
    "#     \"2.500~3.000\":2.750,\n",
    "#     \"3.000~3.500\":3.250,\n",
    "#     \"3.500~4.000\":3.750\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 20 load from circ pre-computed data set\n",
    "# df = pd.read_csv(\"df_fortran_Feb19.csv\")\n",
    "# df = pd.read_csv(\"df_fortran_Feb20.csv\")\n",
    "# df = pd.read_csv(\"df_fortran_Feb23.csv\")\n",
    "df = pd.read_csv(\"df_fortran_Feb24.csv\")\n",
    "\n",
    "df = df.loc[df['dataSet']!=13]\n",
    "df = df.loc[df['dataSet']!=21]\n",
    "df = df.loc[df['dataSet']!=18]\n",
    "df['Hbc_Sig(GeV)']=0.0\n",
    "df['Hbc_error(GeV)']=0.0\n",
    "# df = pd.read_csv(\"df_fortran_Feb15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting purpose only, read Fortran fit for Q2 and qv centers\n",
    "Qvcenter_datas = []\n",
    "for qvcenter in qvcenters:\n",
    "    Qvcenter_data = pd.read_csv('Qvedges/'+f'Qvedge_{qvcenter}.csv',index_col = False)\n",
    "    Qvcenter_data.columns = ['qv','q2','ex','nu','RT','RL','RTQE','RLQE','RTIE','RLIE','RTE','RLE','RTNS','RLNS']\n",
    "    Qvcenter_data['W2']= mass_nucleon**2+2*mass_nucleon*Qvcenter_data['nu']-Qvcenter_data['q2']\n",
    "    Qvcenter_datas.append(Qvcenter_data)\n",
    "\n",
    "\n",
    "Q2center_datas = []\n",
    "for Q2center in Q2centers:\n",
    "    Q2center_data = pd.read_csv('Q2edges/'+f'Q2edge_{Q2center}.csv',index_col = False)\n",
    "    Q2center_data.columns = ['qv','q2','ex','nu','RT','RL','RTQE','RLQE','RTIE','RLIE','RTE','RLE','RTNS','RLNS']\n",
    "    Q2center_data['W2']= mass_nucleon**2+2*mass_nucleon*Q2center_data['nu']-Q2center_data['q2']\n",
    "    Q2center_datas.append(Q2center_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate H_cc, etc. from source data\n",
    "# calculate thetaRad, sin2(T/2), cos2(T/2), tan2(T/2)\n",
    "df[\"ThetaRad\"]=df[\"ThetaDeg\"]*np.pi/180\n",
    "df[\"sin2(T/2)\"]=(np.sin(df[\"ThetaRad\"]/2))**2\n",
    "df[\"cos2(T/2)\"]=(np.cos(df[\"ThetaRad\"]/2))**2\n",
    "df[\"tan2(T/2)\"]=(np.tan(df[\"ThetaRad\"]/2))**2\n",
    "\n",
    "\n",
    "df[\"normalization\"]=df[\"dataSet\"].map(dataSet_to_normalization)\n",
    "df[\"normError\"]=df[\"dataSet\"].map(dataSet_to_normError)\n",
    "\n",
    "# calculate normalized cross section \n",
    "# df[\"cross\"] = df[\"cross\"] * df[\"normalization\"]\n",
    "# df[\"error\"] = df[\"error\"] * df[\"normalization\"]\n",
    "df['normCross'] = df['cross'] * df['normalization']\n",
    "df['normCrossError']=df['normCross']*np.sqrt(\n",
    "        (df['error']/df['cross'])**2+(df['normError']/df['normalization'])**2\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ex = nu - nu_elastic\n",
    "# nu = Ex + nu_elastic\n",
    "# nu_elastic = E0 - E0 / (1 + 2*E0*sin2(T/2) / mass_c12)\n",
    "# Ex = nu - E0 + E0 / (1 + 2*E0*sin2(T/2) / mass_c12)\n",
    "df[\"nu_elastic\"]=df[\"E0\"]-df[\"E0\"]/(1+2*df[\"E0\"]*df[\"sin2(T/2)\"]/mass_C12)\n",
    "\n",
    "\n",
    "# convert yamaguchi, ryan's Ex to nu:\n",
    "# df.loc[df[\"dataSet\"]==16,\"nu\"] = df.loc[df[\"dataSet\"]==16,\"nu\"] + df.loc[df[\"dataSet\"]==16,\"nu_elastic\"]\n",
    "# df.loc[df[\"dataSet\"]==17,\"nu\"] = df.loc[df[\"dataSet\"]==17,\"nu\"] + df.loc[df[\"dataSet\"]==17,\"nu_elastic\"]\n",
    "\n",
    "df[\"Ex\"]=df[\"nu\"]-df[\"nu_elastic\"]\n",
    "\n",
    "\n",
    "df[\"Ex\"] = df[\"nu\"] - (df[\"E0\"]-df[\"E0\"]/(1+2*df[\"E0\"]*df[\"sin2(T/2)\"]/mass_C12))\n",
    "\n",
    "# R = 2.894, Z = 6, A = 12\n",
    "df[\"R\"]=1.1*(df[\"A\"])**(1/3)+0.86/((df[\"A\"])**(1/3))\n",
    "df[\"Veff\"]=0.775*(3/2)*alpha_fine*(df[\"Z\"]-1)/df[\"R\"]\n",
    "# wrong formula?\n",
    "df[\"Veff\"]=0.0031\n",
    "\n",
    "\n",
    "df[\"Eeff\"]=df[\"E0\"]+df[\"Veff\"]\n",
    "\n",
    "df[\"Eprime\"]=df[\"E0\"]-df[\"nu\"]\n",
    "df[\"Eprime_eff\"]=df[\"Eprime\"]+df[\"Veff\"]\n",
    "\n",
    "df[\"F2foc\"]=(df[\"Eeff\"]/df[\"E0\"])**2\n",
    "\n",
    "df[\"Q2\"]=4*df[\"E0\"]*(df[\"Eprime\"])*df[\"sin2(T/2)\"]\n",
    "df[\"Q2eff\"]=4*df[\"Eeff\"]*df[\"Eprime_eff\"]*df[\"sin2(T/2)\"]\n",
    "# df[\"qeff\"]=df[\"Q2eff\"]+df[\"nu\"]**2\n",
    "\n",
    "\n",
    "# df[\"q3momt_squared\"]=df[\"nu\"]**2+df[\"Q2\"]\n",
    "# qeff2\n",
    "df[\"q3momt_squared\"]=df[\"nu\"]**2+df[\"Q2eff\"]\n",
    "# qeff\n",
    "df[\"q3momt\"]=np.sqrt(df[\"q3momt_squared\"])\n",
    "\n",
    "# df[\"W2\"]=mass_nucleon**2+2*mass_nucleon*df[\"nu\"]-df[\"Q2\"]\n",
    "# W2eff\n",
    "df[\"W2\"]=mass_nucleon**2+2*mass_nucleon*df[\"nu\"]-df[\"Q2eff\"]\n",
    "\n",
    "# df[\"W\"]=np.sqrt(df[\"W2\"])\n",
    "\n",
    "# df[\"epsilon\"]=1/(1+2*(1+(df[\"nu\"]**2)/df[\"Q2\"])*df[\"tan2(T/2)\"])\n",
    "# epsilon effective\n",
    "df[\"epsilon\"]=1/(1+2*(1+(df[\"nu\"]**2)/df[\"Q2eff\"])*df[\"tan2(T/2)\"]) \n",
    "\n",
    "\n",
    "## QUESTIONS!!!!!\n",
    "# df[\"gamma\"]=alpha_fine*df[\"Eprime\"]*(df[\"W2\"]-mass_nucleon**2)/((4*((np.pi)**2)*df[\"Q2\"]*mass_nucleon*df[\"E0\"])*(1-df[\"epsilon\"]))\n",
    "df[\"gamma\"]=alpha_fine*df[\"Eprime_eff\"]*(df[\"W2\"]-mass_nucleon**2)/((4*((np.pi)**2)*df[\"Q2eff\"]*mass_nucleon*df[\"E0\"])*(1-df[\"epsilon\"]))\n",
    "\n",
    "# df[\"Sig_R\"]=df[\"cross\"]/df[\"gamma\"]\n",
    "df[\"Sig_R\"]=df[\"normCross\"]/df[\"gamma\"]\n",
    "df[\"D_sig_R\"]=df[\"error\"]/df[\"gamma\"]\n",
    "\n",
    "df[\"Sig_mott\"]=4*(alpha_fine**2)*(df[\"Eprime\"]**2)*df[\"cos2(T/2)\"]/(df[\"Q2\"]**2)\n",
    "# Sig_mott_eff = Sig_mott / F2eff\n",
    "df[\"Sig_mott_eff\"]=df[\"Sig_mott\"]*df[\"E0\"]/df[\"Eeff\"]\n",
    "\n",
    "# df[\"H\"]=(df[\"q3momt_squared\"]**2)/(4*(alpha_fine**2)*(df[\"Eprime\"]**2)*(df[\"cos2(T/2)\"]+2*(df[\"q3momt_squared\"]/df[\"Q2\"])*df[\"sin2(T/2)\"]))\n",
    "df[\"H\"]=(df[\"q3momt_squared\"]**2)/(4*(alpha_fine**2)*(df[\"Eprime_eff\"]**2)*(df[\"cos2(T/2)\"]+2*(df[\"q3momt_squared\"]/df[\"Q2eff\"])*df[\"sin2(T/2)\"]))\n",
    "\n",
    "# H with coloumb correction\n",
    "df[\"Hcc\"]=df[\"H\"] / df[\"F2foc\"]\n",
    "\n",
    "\n",
    "# H without coloumb correction\n",
    "# df[\"Hstar_Sig(nb)\"]=initial_correction*df[\"H\"]*df[\"cross\"]\n",
    "# df[\"Hstar_error(nb)\"]=initial_correction*df[\"H\"]*df[\"error\"]\n",
    "df[\"Hstar_Sig(nb)\"]=initial_correction*df[\"H\"]*df[\"normCross\"]\n",
    "df[\"Hstar_error(nb)\"]=initial_correction*df[\"H\"]*df[\"normCrossError\"]\n",
    "df[\"Hstar_Sig(GeV)\"]=df[\"Hstar_Sig(nb)\"]/((0.1973269**2)*10000000)\n",
    "df[\"Hstar_error(GeV)\"]=df[\"Hstar_error(nb)\"]/((0.1973269**2)*10000000)\n",
    "\n",
    "# H with coloumb correction\n",
    "# df[\"Hcc_Sig(nb)\"]=initial_correction*df[\"Hcc\"]*df[\"cross\"]\n",
    "# df[\"Hcc_error(nb)\"]=initial_correction*df[\"Hcc\"]*df[\"error\"]\n",
    "df[\"Hcc_Sig(nb)\"]=initial_correction*df[\"Hcc\"]*df[\"normCross\"]\n",
    "df[\"Hcc_error(nb)\"]=initial_correction*df[\"Hcc\"]*df[\"normCrossError\"]\n",
    "df[\"Hcc_Sig(GeV)\"]=df[\"Hcc_Sig(nb)\"]/((0.1973269**2)*10000000)\n",
    "df[\"Hcc_error(GeV)\"]=df[\"Hcc_error(nb)\"]/((0.1973269**2)*10000000)\n",
    "\n",
    "df['qvbin'] = 0\n",
    "df['qvcenter'] = 0\n",
    "df['Q2bin'] = 0\n",
    "df['Q2center'] = 0\n",
    "\n",
    "df[\"qvbin\"]=pd.cut(x=df[\"q3momt\"],bins=qvbins,labels=qvbin_names,right=True)\n",
    "df[\"qvcenter\"]=pd.cut(x=df[\"q3momt\"],bins=qvbins,labels=qvcenters,right=True)\n",
    "df['qvcenter']=pd.to_numeric(df['qvcenter'])\n",
    "\n",
    "df[\"Q2bin\"]=pd.cut(x=df[\"Q2\"],bins=Q2bins,labels=Q2bin_names,right=True)\n",
    "df[\"Q2center\"]=pd.cut(x=df[\"Q2\"],bins=Q2bins,labels=Q2centers,right=True)\n",
    "df['Q2center']=pd.to_numeric(df['Q2center'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all bin centering correction factors: in Ex or in nu? for qv or for q2?\n",
    "# qv*qv = Q2 + nu*nu\n",
    "# Q2 = qv*qv - nu*nu\n",
    "\n",
    "# bin centering correction for qv bin in Ex:\n",
    "df[\"bc_qv_ex\"]=1.0\n",
    "for qvcenter in qvcenters:\n",
    "    picked = df.loc[df[\"qvcenter\"]==qvcenter]\n",
    "\n",
    "    for index, row in picked.iterrows():\n",
    "        if row['qvcenter']!= float('NaN'):\n",
    "            if row['Ex']<=0.025:\n",
    "                continue\n",
    "            try:\n",
    "                row['bc_qv_ex']= (row['epsilon']*row['RL_fortran_qvcenter_ex']+0.5*((row['qvcenter']**2\n",
    "                                                        )/(row['qvcenter']**2-row['nu']**2)\n",
    "                                                    )*row['RT_fortran_qvcenter_ex']\n",
    "                    )/(row['epsilon']*row['RL_fortran_qvdata_ex']+0.5*(row['q3momt_squared']/row['Q2eff'])*row['RT_fortran_qvdata_ex'])\n",
    "            except ZeroDivisionError:\n",
    "                print('ZeroDivisionError, index:',index,'qvcenter:',qvcenter,'nu:',row['nu'],\n",
    "                      'Ex:',row['Ex'],'RT_fortran_qvdata_ex:',row['RT_fortran_qvdata_ex'])\n",
    "            \n",
    "\n",
    "# bin centering correction for qv bin in nu:\n",
    "df[\"bc_qv_nu\"]=1.0\n",
    "for qvcenter in qvcenters:\n",
    "    picked = df.loc[df[\"qvcenter\"]==qvcenter]\n",
    "\n",
    "    for index, row in picked.iterrows():\n",
    "        if row['qvcenter']!= float('NaN'):\n",
    "            if row['Ex']<=0.025:\n",
    "                continue\n",
    "            try:\n",
    "               row['bc_qv_nu']= (row['epsilon']*row['RL_fortran_qvcenter_nu']+0.5*((row['qvcenter']**2\n",
    "                                                        )/(row['qvcenter']**2-row['nu']**2)\n",
    "                                                    )*row['RT_fortran_qvcenter_nu']\n",
    "                    )/(row['epsilon']*row['RL_fortran_qvdata_nu']+0.5*(row['q3momt_squared']/row['Q2eff'])*row['RT_fortran_qvdata_nu'])\n",
    "            except ZeroDivisionError:\n",
    "                print('ZeroDivisionError, index:',index,'qvcenter:',qvcenter,'nu:',row['nu'],\n",
    "                      'Ex:',row['Ex'],'RT_fortran_qvdata_nu:',row['RT_fortran_qvdata_nu'])\n",
    "                \n",
    "\n",
    "# bin centering correction for qv bin in W2:\n",
    "df[\"bc_qv_w2\"]=1.0\n",
    "for qvcenter in qvcenters:\n",
    "    picked = df.loc[df[\"qvcenter\"]==qvcenter]\n",
    "\n",
    "    for index, row in picked.iterrows():\n",
    "        if row['qvcenter']!= float('NaN'):\n",
    "            if row['Ex']<=0.025:\n",
    "                continue\n",
    "            try:\n",
    "               row['bc_qv_w2']= (row['epsilon']*row['RL_fortran_qvcenter_w2']+0.5*((row['qvcenter']**2\n",
    "                                                        )/(\n",
    "                                                            2*mass_nucleon*np.sqrt(row['qvcenter']**2+row['W2'])-row['W2']-mass_nucleon**2\n",
    "                                                        )\n",
    "                                                    )*row['RT_fortran_qvcenter_w2']\n",
    "                    )/(row['epsilon']*row['RL_fortran_qvdata_w2']+0.5*(row['q3momt_squared']/row['Q2eff'])*row['RT_fortran_qvdata_w2'])\n",
    "            except ZeroDivisionError:\n",
    "                print('ZeroDivisionError, index:',index)\n",
    "\n",
    "\n",
    "# bin centering correction for q2 bin in Ex:\n",
    "df[\"bc_q2_ex\"]=1.0\n",
    "for Q2center in Q2centers:\n",
    "    picked = df.loc[df[\"Q2center\"]==Q2center]\n",
    "\n",
    "    for index, row in picked.iterrows():\n",
    "        if row['Ex']<=0.025:\n",
    "            continue\n",
    "        row['bc_q2_ex']= (row['epsilon']*row['RL_fortran_q2center_ex']+0.5*((Q2center+row[\"nu\"]**2\n",
    "                                                    )/(row[\"Q2center\"])\n",
    "                                                )*row['RT_fortran_q2center_ex']\n",
    "                )/(row['epsilon']*row['RL_fortran_q2data_ex']+0.5*(row['q3momt_squared']/row['Q2eff'])*row['RT_fortran_q2data_ex'])\n",
    "        \n",
    "# bin centering correction for q2 bin in nu:\n",
    "df[\"bc_q2_nu\"]=1.0\n",
    "for Q2center in Q2centers:\n",
    "    picked = df.loc[df[\"Q2center\"]==Q2center]\n",
    "\n",
    "    for index, row in picked.iterrows():\n",
    "        if row['Ex']<=0.025:\n",
    "            continue\n",
    "        row['bc_q2_nu']= (row['epsilon']*row['RL_fortran_q2center_nu']+0.5*((Q2center+row[\"nu\"]**2\n",
    "                                                    )/(row[\"Q2center\"])\n",
    "                                                )*row['RT_fortran_q2center_nu']\n",
    "                )/(row['epsilon']*row['RL_fortran_q2data_nu']+0.5*(row['q3momt_squared']/row['Q2eff'])*row['RT_fortran_q2data_nu'])\n",
    "\n",
    "# bin centering correction for q2 bin in W2:\n",
    "df[\"bc_q2_w2\"]=1.0\n",
    "for Q2center in Q2centers:\n",
    "    picked = df.loc[df[\"Q2center\"]==Q2center]\n",
    "\n",
    "    for index, row in picked.iterrows():\n",
    "        if row['Ex']<=0.025:\n",
    "            continue\n",
    "        nu = (row['W2']+Q2center-mass_nucleon**2)/(2*mass_nucleon)\n",
    "        qv2center = Q2center+nu**2\n",
    "        row['bc_q2_w2']= (row['epsilon']*row['RL_fortran_q2center_w2']+0.5*(\n",
    "                                                        qv2center/(row[\"Q2center\"])\n",
    "                                                )*row['RT_fortran_q2center_w2']\n",
    "                )/(row['epsilon']*row['RL_fortran_q2data_w2']+0.5*(row['q3momt_squared']/row['Q2eff'])*row['RT_fortran_q2data_w2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 7 notes:\n",
    "'''\n",
    "q3=0.205:\n",
    "\n",
    "\n",
    "q3=0.24:\n",
    "\n",
    "q3=0.475:\n",
    "At larger nu (>0.25), there's a lot of negative RL values with large error bars.\n",
    "RT values are large.\n",
    "Possible reasons: Baran data (4) has low Hbc at large epsilon.\n",
    "\n",
    "q3=0.57:\n",
    "Same thing happened here. Baran's data is pulling the fit down.\n",
    "After dropping Baran, there's still a drop of RL at nu=0.3. However,\n",
    "the included data sets are just 1, 3, 5, 8 across nu=0.3.\n",
    "Possible solution: increase dataset 3 Sealock and 5 Bagdasaryan's cross section.\n",
    "\n",
    "q3=0.649:\n",
    "Same thing happened here.\n",
    "Fixed after dropping Baran.\n",
    "\n",
    "\n",
    "normalization error of dataset 22, 23?\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_columns = [18]\n",
    "\n",
    "nuwidth = nuwidths[inspect_columns[0]]\n",
    "print(qvcenters[inspect_columns[0]])\n",
    "totalChi2 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invesiagte the curve fit, qvbin\n",
    "\n",
    "# df[\"Hbc_Sig(GeV)\"]=df[\"Hcc_Sig(GeV)\"]\n",
    "# df[\"Hbc_error(GeV)\"]=df[\"Hcc_error(GeV)\"]\n",
    "df[\"Hbc_Sig(GeV)\"]=df[\"bc_qv_nu\"]*df[\"Hcc_Sig(GeV)\"]\n",
    "df[\"Hbc_error(GeV)\"]=df[\"bc_qv_nu\"]*df[\"Hcc_error(GeV)\"]\n",
    "\n",
    "Photon_plotting = pd.read_csv(\"Photon_plotting.csv\")\n",
    "Ryan = pd.read_csv(\"Ryan_bin_centered.csv\")\n",
    "def append_row(df, row):\n",
    "    return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
    "\n",
    "# eq. 28: for theta = 180,\n",
    "# RT = ((E0/(E0+Veff))**2) * ((Q2eff/(2*alpha*Eprime_eff))**2 ) * cross\n",
    "df_Ryan = df.loc[df['dataSet']==17].copy()\n",
    "df_Ryan['RT28'] = (\n",
    "        (df_Ryan['E0']/df_Ryan['Eeff'])**2\n",
    "    )*(\n",
    "       (df_Ryan['Q2eff']/(\n",
    "              2*alpha_fine*df_Ryan['Eprime_eff']\n",
    "       ))**2 \n",
    "    )*df_Ryan['cross']/(((0.1973269**2)*1e10))\n",
    "\n",
    "\n",
    "def linear_model(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "Yamaguchi_qvs = [0.148,0.167,0.205,0.24,0.3]\n",
    "Jourdan_qvs = [0.3,0.38,0.57]\n",
    "Barr_qvs = [0.3,0.4,0.55,]\n",
    "# Create a PdfPages object to save plots to a PDF file\n",
    "fit = pd.DataFrame(columns=['nu','RL','RLerr','RT','RTerr','Chi2',\n",
    "                                    'num_points'])\n",
    "# with PdfPages('curve_fit/curve_fit_'+str(qvcenters[inspect_columns])+'.pdf') as pdf:\n",
    "for i in inspect_columns:\n",
    "    with PdfPages('curve_fit/curve_fit_qv_'+str(qvcenters[i])+'.pdf') as pdf:\n",
    "        qvcenter = qvcenters[i]\n",
    "        qvcenter_data = Qvcenter_datas[i]\n",
    "        qv2center = qvcenter**2\n",
    "        qv_bot = qvbins[i]\n",
    "        qv_top = qvbins[i+1]\n",
    "        qvbin_name = qvbin_names[i]\n",
    "        W2width = W2widths[i]\n",
    "        Exwidth = 0.02\n",
    "        bin_data = df.loc[df['qvcenter']==qvcenter].copy()\n",
    "        # drop dataset 13, 18, 19, 21\n",
    "\n",
    "\n",
    "        \n",
    "        RLs = []\n",
    "        RLerrs = []\n",
    "        RTs = []\n",
    "        RTerrs = []\n",
    "        nus = []\n",
    "        RxQ2s = []\n",
    "        RxQ2_errs = []\n",
    "        Exs = []\n",
    "        Ex_grid = np.arange(0.0,0.5,0.01)\n",
    "\n",
    "        # formulate 0 < nu < q3\n",
    "        nu_grid = np.arange(0.0,qvcenter,nuwidth*2)\n",
    "\n",
    "        \n",
    "        for nu in nu_grid:\n",
    "        # for Ex in Ex_grid:\n",
    "            Ex = nu-(qvcenter**2-nu**2)/(2*mass_C12)\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            # q3momt_squared = Q2center+nu**2\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            Q2 = qvcenter**2-nu**2\n",
    "            W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2\n",
    "            # if Ex >= 0.05:\n",
    "            #     width = 0.01\n",
    "            # else:\n",
    "            #     width = 0.01\n",
    "\n",
    "            # picked = bin_data.loc[(W2<=bin_data[\"W2\"]) & (bin_data[\"W2\"]<=(W2+2*W2width)) & (bin_data['Ex']>0.025)]\n",
    "            # picked = bin_data.loc[((Ex-Exwidth)<=df[\"Ex\"]) & (df[\"Ex\"]<=(Ex+Exwidth)) & (0.030<=df[\"Ex\"])]\n",
    "            # picked = bin_data.loc[((nu-nuwidth)<=df[\"nu\"]) & (df[\"nu\"]<=(nu+nuwidth)) & (0.030<=df[\"Ex\"])]\n",
    "            picked = bin_data.loc[((nu-nuwidth)<=bin_data[\"nu\"]) & (bin_data[\"nu\"]<=(nu+nuwidth))]\n",
    "\n",
    "\n",
    "\n",
    "            # picked = picked.drop_duplicates(keep=\"last\")\n",
    "            x = np.array(picked[\"epsilon\"].values)\n",
    "            y = np.array(picked[\"Hbc_Sig(GeV)\"].values)\n",
    "            y_err = np.array(picked[\"Hbc_error(GeV)\"].values)\n",
    "            \n",
    "            if len(y)>2 and (np.max(x)-np.min(x))>=0.25:\n",
    "                if len(y)==2:\n",
    "                    # print(\"len(y)==2\")\n",
    "                    # duplicated_values = np.concatenate([original_values + 0.1 * original_errors,\n",
    "                    #                     original_values - 0.1 * original_errors])\n",
    "                    # duplicated_errors = original_errors * 1.414\n",
    "                    # duplicated_errors = np.repeat(duplicated_errors, 2)  # Repeat each error twice\n",
    "                    x = np.concatenate([x, x])\n",
    "                    y = np.concatenate([y+0.1*y_err, y-0.1*y_err])\n",
    "                    y_err = y_err * 1.414\n",
    "                    y_err = np.concatenate([y_err, y_err])\n",
    "\n",
    "                params, covariance = curve_fit(linear_model, x, y, sigma=y_err, absolute_sigma=True)\n",
    "\n",
    "                a_opt, b_opt = params\n",
    "                a_err, b_err = np.sqrt(np.diag(covariance))\n",
    "                Chi2 = np.sum(np.square((y-linear_model(x,a_opt,b_opt))/y_err))\n",
    "                RL = a_opt/1000\n",
    "                RT = (2*b_opt*Q2/qv2center)/1000\n",
    "                # if RL>=0 and RT>=0:\n",
    "                RLs.append(RL)\n",
    "                RLerr = a_err/1000 \n",
    "                RLerrs.append(RLerr)\n",
    "                RTs.append(RT)\n",
    "                RTerr = (2*b_err*Q2/qv2center)/1000\n",
    "                RTerrs.append(RTerr)\n",
    "                RxQ2s.append( (2*Q2/qv2center)*RL/RT)\n",
    "                RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
    "                RxQ2_errs.append(RxQ2_err)\n",
    "                # W2s.append(W2)\n",
    "                nus.append(nu)\n",
    "\n",
    "                # new_row = {'A': 1, 'B': 2, 'C': 3}   \n",
    "                new_row = pd.Series({'nu':nu,'RL':RL,'RLerr':RLerr,'RT':RT,'RTerr':RTerr,'Chi2':Chi2,\n",
    "                                    'num_points':len(y)})             \n",
    "                fit = append_row(fit,new_row)\n",
    "#____________________________________________________________________________________________________________________\n",
    "                # if nu >= 0.15:\n",
    "                fig = plt.figure(figsize=(10,4))\n",
    "                plt.plot(x,linear_model(x,a_opt,b_opt),color='gray',label = 'y='+str(round(a_opt,3))\n",
    "                        +'*x+'+str(round(b_opt,3))+'\\nRL,RT:'+str(round(RL,3))+','+str(round(RT,3)))\n",
    "                datasets = picked['dataSet'].unique()\n",
    "                            \n",
    "                plt.title('$Q^{3}_{center}$:'+str(qvcenter)+'   Ex:'+str(round(Ex,3))+'   nu:'+str(nu)+'    RL,RT error: '+round_sig_3(RLerr)+','+round_sig_3(RTerr)\n",
    "                          +'   $\\chi^2$:'+str(round(Chi2,1))+'   DoF:'+str(len(y)-2) +'   $\\\\frac{\\chi^2}{DoF}$:'+str(round(Chi2/(len(y)-2),1)))\n",
    "\n",
    "                for dataset in datasets:\n",
    "                    picked_dataset = picked.loc[picked['dataSet']==dataset]\n",
    "                    plt.errorbar(picked_dataset['epsilon'],picked_dataset['Hbc_Sig(GeV)'],yerr=picked_dataset['Hbc_error(GeV)'],\n",
    "                                 fmt ='.',capsize=3,markersize='3')\n",
    "                    plt.scatter(picked_dataset['epsilon'],picked_dataset['Hbc_Sig(GeV)'],s=10, label = str(dataset)+' '+dataSet_to_name[dataset])\n",
    "\n",
    "                # plt.scatter(x,y,s=1)\n",
    "                plt.xlabel('epsilon')\n",
    "                plt.ylabel('Hbc')\n",
    "                plt.legend()\n",
    "                pdf.savefig(fig)\n",
    "#____________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "        # fit = pd.DataFrame({'nu':nus,'RL':RLs,'RLerr':RLerrs,'RT':RTs,'RTerr':RTerrs})\n",
    "        fit['Chi2_DoF']=fit['Chi2']/(fit['num_points']-2)\n",
    "        # fit = fit.loc[fit['RL']>=-0.08]\n",
    "        # drop thelargest RL errors\n",
    "        \n",
    "        fit = fit.drop(fit['Chi2_DoF'].idxmax())\n",
    "\n",
    "        # fit = fit.drop(fit['RLerr'].idxmax())\n",
    "\n",
    "        # fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # 1 row, 3 columns\n",
    "        # fig, axs = plt.subplots(1, 2, figsize=(10, 5))  # 1 row, 2 columns\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(10, 15))  # 3 row, 1 columns\n",
    "\n",
    "\n",
    "        tick_spacing = 0.05\n",
    "\n",
    "        # photo-production data\n",
    "        photon_index = (Photon_plotting['qv'] - qvcenter).abs().idxmin()\n",
    "        photon_data = Photon_plotting.loc[photon_index]\n",
    "\n",
    "        try:\n",
    "            responseq2_plotting = qvcenter_data.loc[qvcenter_data['nu']<=qvcenter*0.95]\n",
    "            # responseq2_plotting = qvcenter_data.loc[qvcenter_data['nu']<=photon_data['nu']]\n",
    "            # responseq2_plotting = picked.loc[picked['nu']<=np.max(nus)]\n",
    "        except ValueError:\n",
    "            print(\"ValueError: no data points\")\n",
    "        axs[0].plot(responseq2_plotting['nu'],responseq2_plotting[\"RL\"],label=\"Fortran RL\", linestyle='dotted',color='black')    \n",
    "        # axs[0].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RL_fortran_qvcenter_nu\"],label=\"Fortran RL\", s=3,color='black')    \n",
    "        axs[0].errorbar(fit['nu'], fit['RL'], yerr = fit['RLerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[0].scatter(fit['nu'], fit['RL'],marker='D',s=6,color='red',label=\"$Q3_{center}:$\"+str(qvcenter))\n",
    "        axs[0].set_title(\"$Q3$:\"+qvbin_name)\n",
    "        axs[0].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[0].set_ylabel(\"$R_L$\")\n",
    "        axs[0].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[0].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        axs[1].plot(responseq2_plotting['nu'],responseq2_plotting[\"RT\"],label=\"Fortran RT\",linestyle='dotted',color='black')\n",
    "        # axs[1].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RT_fortran_qvcenter_nu\"],label=\"Fortran RT\", s=3,color='black')\n",
    "        axs[1].errorbar(fit['nu'], fit['RT'], yerr = fit['RTerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[1].scatter(fit['nu'], fit['RT'],marker='D',s=6,color='red',label=\"$Q3_{center}:$\"+str(qvcenter))\n",
    "        axs[1].set_title(\"$Q3$:\"+qvbin_name)\n",
    "        axs[1].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[1].set_ylabel(\"$R_T$\")\n",
    "        axs[1].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[1].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        # photon-production data\n",
    "        axs[1].scatter(photon_data['nu'],photon_data[\"RT\"],marker='^',s=30,color='lime',label=\"Photo-production\")\n",
    "\n",
    "        if qvcenter in Ryan['qvcenter'].unique():\n",
    "            # Ryan_data = Ryan.loc[Ryan['qvcenter']==qvcenter]\n",
    "            # axs[1].errorbar(Ryan_data['nu'],Ryan_data[\"RT_bc\"], yerr = Ryan_data[\"RTerr_bc\"], color='plum', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[1].scatter(Ryan_data['nu'],Ryan_data[\"RT_bc\"],marker='D',s=6,color='plum',label=\"Ryan bin_centered\")\n",
    "\n",
    "            Ryan_data = df_Ryan.loc[df_Ryan['qvcenter']==qvcenter]\n",
    "            axs[1].scatter(Ryan_data['nu'],Ryan_data[\"RT28\"],marker='D',s=6,color='plum',label=\"Ryan bin_centered\")\n",
    "\n",
    "        \n",
    "        if qvcenter in Jourdan_qvs:\n",
    "            Jourdan_data = pd.read_excel('Jourdan_RL_RT_plots.xlsx')\n",
    "            Jourdan_data = Jourdan_data.loc[Jourdan_data['Q']==qvcenter]\n",
    "            axs[0].errorbar(Jourdan_data['nu'],Jourdan_data[\"RL\"], yerr = Jourdan_data[\"Error(RL)\"], color='darkred', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[0].scatter(Jourdan_data['nu'],Jourdan_data[\"RL\"],marker='D',s=6,color='darkred',label=\"Jourdan\")\n",
    "            axs[1].errorbar(Jourdan_data['nu'],Jourdan_data[\"RT\"], yerr = Jourdan_data[\"Error(RT)\"], color='darkred', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Jourdan_data['nu'],Jourdan_data[\"RT\"],marker='D',s=6,color='darkred',label=\"Jourdan\")\n",
    "        \n",
    "            # plot barreau along with Ryan\n",
    "            \n",
    "            if qvcenter == 0.3:\n",
    "                bar_qv = 0.3    \n",
    "            if qvcenter == 0.38:\n",
    "                bar_qv = 0.4\n",
    "            elif qvcenter == 0.57:\n",
    "                bar_qv = 0.55\n",
    "            \n",
    "            Bar_RL = pd.read_excel('Barreau_plotting.xlsx',sheet_name='RL_qv_'+str(bar_qv))\n",
    "            Bar_RL.columns = ['qv','nu','RL','RLerr']\n",
    "            axs[0].errorbar(Bar_RL['nu'],Bar_RL[\"RL\"], yerr = Bar_RL[\"RLerr\"], color='steelblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[0].scatter(Bar_RL['nu'],Bar_RL[\"RL\"],marker='D',s=6,color='blue',label=\"Barreau qv=\"+str(bar_qv))\n",
    "            Bar_RT = pd.read_excel('Barreau_plotting.xlsx',sheet_name='RT_qv_'+str(bar_qv))\n",
    "            Bar_RT.columns = ['qv','nu','RT','RTerr']\n",
    "            axs[1].errorbar(Bar_RT['nu'],Bar_RT[\"RT\"], yerr = Bar_RT[\"RTerr\"], color='steelblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Bar_RT['nu'],Bar_RT[\"RT\"],marker='D',s=6,color='blue',label=\"Barreau qv=\"+str(bar_qv))\n",
    "\n",
    "        if qvcenter in Yamaguchi_qvs:\n",
    "            Yam_data = pd.read_excel('Yamaguchi_plotting.xlsx',sheet_name='qv_'+str(qvcenter))\n",
    "            # Yam_data['nu_RL'] = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Yam_data['EX_RL'])\n",
    "            # Yam_data['nu_RT'] = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Yam_data['EX_RT'])\n",
    "            # Ex = nu-(qv^2-nu^2)/(2M)\n",
    "            # nu = - M + sqrt(M^2 + qv^2 + 2M*Ex)\n",
    "            # solve quadratic equation\n",
    "            \n",
    "            # axs[0].errorbar(Yam_data['nu_RL'],Yam_data[\"RL\"], yerr = Yam_data[\"RL\"]*0.03, color='lightpink', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[0].scatter(Yam_data['nu_RL'],Yam_data[\"RL\"],marker='D',s=6,color='skyblue',label=\"Yamaguchi\")\n",
    "            # axs[1].errorbar(Yam_data['nu_RT'],Yam_data[\"RT\"], yerr = Yam_data[\"RT\"]*0.03, color='lightpink', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Yam_data['nu_RT'],Yam_data[\"RT\"],marker='D',s=6,color='skyblue',label=\"Yamaguchi\")  \n",
    "            \n",
    "        # goldemberg\n",
    "        if qvcenter == 0.1: \n",
    "            Goldem_data = pd.read_csv('Goldemberger_180.csv')\n",
    "            axs[1].errorbar(Goldem_data['nu'],Goldem_data[\"RT\"], yerr = Goldem_data[\"error\"], color='skyblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Goldem_data['nu'],Goldem_data[\"RT\"],marker='D',s=6,color='blue',label=\"Goldemberger\")\n",
    "\n",
    "        # W2_peaks = np.array([0.93,1.07,1.23])\n",
    "        W_peaks = np.array([0.93,1.07,1.23]) \n",
    "        W_colors = ['orangered','forestgreen','royalblue']\n",
    "        # 0.8649, 1.1449, 1.5129\n",
    "        for i in range(len(W_peaks)):\n",
    "            axs[0].axvline(x=0.025-mass_nucleon+np.sqrt(qvcenter**2+W_peaks[i]**2), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            axs[1].axvline(x=0.025-mass_nucleon+np.sqrt(qvcenter**2+W_peaks[i]**2), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "        axs[0].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(qvcenter))\n",
    "        axs[1].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(qvcenter))\n",
    "\n",
    "\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "        # fig.savefig('figs/FitEx_Qv_'+str(qvcenter)+'.png')\n",
    "\n",
    "        axs[2].scatter(fit['nu'],fit['Chi2_DoF'],color='orange',s=10)\n",
    "        axs[2].set_title('$\\chi^2/DoF$')\n",
    "        axs[2].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[2].set_ylabel(\"$\\chi^2/DoF$\")\n",
    "        axs[2].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[2].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "        totalChi2 = np.sum(fit['Chi2'])\n",
    "\n",
    "\n",
    "        axs[0].set_xlim(0.0, qvcenter*1.02)\n",
    "        axs[1].set_xlim(0.0, qvcenter*1.02)\n",
    "        axs[2].set_xlim(0.0, qvcenter*1.02)\n",
    "        if qvcenter >= 0.38:\n",
    "            axs[0].set_ylim(np.min([np.min(fit['RL'])*1.02,0]),np.max(fit['RL'])*1.02)\n",
    "            axs[1].set_ylim(np.min([np.min(fit['RT'])*1.02,0]),np.max(fit['RT'])*1.02)\n",
    "            axs[2].set_ylim(0.0,np.max(fit['Chi2_DoF'])*1.02)\n",
    "\n",
    "        axs[0].legend()\n",
    "        axs[1].legend()\n",
    "        axs[2].legend()\n",
    "\n",
    "        plt.tight_layout()  # Optional, for better spacing between subplots\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_columns = [1]\n",
    "\n",
    "nuwidth = nuwidths[inspect_columns[0]]\n",
    "print(Q2centers[inspect_columns[0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invesiagte the curve fit, q2 bin\n",
    "df[\"Hbc_Sig(GeV)\"]=df[\"bc_q2_nu\"]*df[\"Hcc_Sig(GeV)\"]\n",
    "df[\"Hbc_error(GeV)\"]=df[\"bc_q2_nu\"]*df[\"Hcc_error(GeV)\"]\n",
    "\n",
    "Photon_plotting = pd.read_csv(\"Photon_plotting.csv\")\n",
    "Ryan = pd.read_csv(\"Ryan_bin_centered.csv\")\n",
    "def append_row(df, row):\n",
    "    return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def linear_model(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "fit = pd.DataFrame(columns=['nu','RL','RLerr','RT','RTerr','Chi2',\n",
    "                                    'num_points'])\n",
    "# with PdfPages('curve_fit/curve_fit_'+str(qvcenters[inspect_columns])+'.pdf') as pdf:\n",
    "for i in inspect_columns:\n",
    "    with PdfPages('curve_fit/curve_fit_q2_'+str(Q2centers[i])+'.pdf') as pdf:\n",
    "        Q2center = Q2centers[i]\n",
    "        Q2center_data = Q2center_datas[i]\n",
    "        qvcenter = qvcenters[i]\n",
    "        # qvcenter_data = Qvcenter_datas[i]\n",
    "        # qv2center = qvcenter**2\n",
    "        Q2bin_name = Q2bin_names[i]\n",
    "        W2width = W2widths[i]\n",
    "        Exwidth = 0.02\n",
    "        bin_data = df.loc[df['Q2center']==Q2center].copy()\n",
    "        # drop dataset 13, 18, 19, 21\n",
    "\n",
    "\n",
    "        \n",
    "        RLs = []\n",
    "        RLerrs = []\n",
    "        RTs = []\n",
    "        RTerrs = []\n",
    "        nus = []\n",
    "        RxQ2s = []\n",
    "        RxQ2_errs = []\n",
    "        Exs = []\n",
    "\n",
    "        # formulate 0 < nu < q3\n",
    "        nu_grid = np.arange(0.0,2.5,nuwidth*2)\n",
    "\n",
    "        \n",
    "        for nu in nu_grid:\n",
    "        # for Ex in Ex_grid:\n",
    "            Ex = nu-Q2center/(2*mass_C12)\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            # q3momt_squared = Q2center+nu**2\n",
    "            qv2 = Q2center+nu**2\n",
    "            # Q2 = qvcenter**2-nu**2\n",
    "            W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2center\n",
    "            # if Ex >= 0.05:\n",
    "            #     width = 0.01\n",
    "            # else:\n",
    "            #     width = 0.01\n",
    "\n",
    "            # picked = bin_data.loc[(W2<=bin_data[\"W2\"]) & (bin_data[\"W2\"]<=(W2+2*W2width)) & (bin_data['Ex']>0.025)]\n",
    "            # picked = bin_data.loc[((Ex-Exwidth)<=df[\"Ex\"]) & (df[\"Ex\"]<=(Ex+Exwidth)) & (0.030<=df[\"Ex\"])]\n",
    "            # picked = bin_data.loc[((nu-nuwidth)<=df[\"nu\"]) & (df[\"nu\"]<=(nu+nuwidth)) & (0.030<=df[\"Ex\"])]\n",
    "            picked = bin_data.loc[((nu-nuwidth)<=bin_data[\"nu\"]) & (bin_data[\"nu\"]<=(nu+nuwidth))]\n",
    "\n",
    "\n",
    "            # picked = picked.drop_duplicates(keep=\"last\")\n",
    "            x = np.array(picked[\"epsilon\"].values)\n",
    "            y = np.array(picked[\"Hbc_Sig(GeV)\"].values)\n",
    "            y_err = np.array(picked[\"Hbc_error(GeV)\"].values)\n",
    "            \n",
    "            if len(y)>=2 and (np.max(x)-np.min(x))>=0.2:\n",
    "                if len(y)==2:\n",
    "                    # print(\"len(y)==2\")\n",
    "                    # duplicated_values = np.concatenate([original_values + 0.1 * original_errors,\n",
    "                    #                     original_values - 0.1 * original_errors])\n",
    "                    # duplicated_errors = original_errors * 1.414\n",
    "                    # duplicated_errors = np.repeat(duplicated_errors, 2)  # Repeat each error twice\n",
    "                    x = np.concatenate([x, x])\n",
    "                    y = np.concatenate([y+0.1*y_err, y-0.1*y_err])\n",
    "                    y_err = y_err * 1.414\n",
    "                    y_err = np.concatenate([y_err, y_err])\n",
    "                params, covariance = curve_fit(linear_model, x, y, sigma=y_err, absolute_sigma=True)\n",
    "                a_opt, b_opt = params\n",
    "                a_err, b_err = np.sqrt(np.diag(covariance))\n",
    "                Chi2 = np.sum(np.square((y-linear_model(x,a_opt,b_opt))/y_err))\n",
    "                RL = a_opt/1000\n",
    "                RT = (2*b_opt*Q2center/qv2)/1000\n",
    "                # if RL>=0 and RT>=0:\n",
    "                RLs.append(RL)\n",
    "                RLerr = a_err/1000 \n",
    "                RLerrs.append(RLerr)\n",
    "                RTs.append(RT)\n",
    "                RTerr = (2*b_err*Q2center/qv2)/1000\n",
    "                RTerrs.append(RTerr)\n",
    "                RxQ2s.append( (2*Q2center/qv2)*RL/RT)\n",
    "                RxQ2_err = np.abs ((2*Q2center/qv2)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
    "                RxQ2_errs.append(RxQ2_err)\n",
    "                # W2s.append(W2)\n",
    "                nus.append(nu)\n",
    "\n",
    "                # new_row = {'A': 1, 'B': 2, 'C': 3}   \n",
    "                new_row = pd.Series({'nu':nu,'RL':RL,'RLerr':RLerr,'RT':RT,'RTerr':RTerr,'Chi2':Chi2,\n",
    "                                    'num_points':len(y)})             \n",
    "                fit = append_row(fit,new_row)\n",
    "#____________________________________________________________________________________________________________________\n",
    "                # if nu >= 0.15:\n",
    "                fig = plt.figure(figsize=(10,4))\n",
    "                plt.plot(x,linear_model(x,a_opt,b_opt),color='gray',label = 'y='+str(round(a_opt,3))\n",
    "                        +'*x+'+str(round(b_opt,3))+'\\nRL,RT:'+str(round(RL,3))+','+str(round(RT,3)))\n",
    "                datasets = picked['dataSet'].unique()\n",
    "                            \n",
    "                plt.title('$Q^{2}_{center}$:'+str(Q2center)+'   Ex:'+str(round(Ex,3))+'   nu:'+str(nu)+'    RL,RT error: '+round_sig_3(RLerr)+','+round_sig_3(RTerr)\n",
    "                          +'   $\\chi^2$:'+str(round(Chi2,1))+'   DoF:'+str(len(y)-2) +'   $\\\\frac{\\chi^2}{DoF}$:'+str(round(Chi2/(len(y)-2),1)))\n",
    "\n",
    "                for dataset in datasets:\n",
    "                    picked_dataset = picked.loc[picked['dataSet']==dataset]\n",
    "                    plt.errorbar(picked_dataset['epsilon'],picked_dataset['Hbc_Sig(GeV)'],yerr=picked_dataset['Hbc_error(GeV)'],\n",
    "                                 fmt ='.',capsize=3,markersize='3')\n",
    "                    plt.scatter(picked_dataset['epsilon'],picked_dataset['Hbc_Sig(GeV)'],s=10, label = str(dataset)+' '+dataSet_to_name[dataset])\n",
    "\n",
    "                # plt.scatter(x,y,s=1)\n",
    "                plt.xlabel('epsilon')\n",
    "                plt.ylabel('Hbc')\n",
    "                plt.legend()\n",
    "                pdf.savefig(fig)\n",
    "#____________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "        # fit = pd.DataFrame({'nu':nus,'RL':RLs,'RLerr':RLerrs,'RT':RTs,'RTerr':RTerrs})\n",
    "        fit['Chi2_DoF']=fit['Chi2']/(fit['num_points']-2)\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(10, 15))  # 3 row, 1 columns\n",
    "\n",
    "\n",
    "        tick_spacing = 0.05\n",
    "\n",
    "\n",
    "        try:\n",
    "            responseq2_plotting = Q2center_data.loc[Q2center_data['nu']<=fit['nu'].max()]\n",
    "            # responseq2_plotting = qvcenter_data.loc[qvcenter_data['nu']<=photon_data['nu']]\n",
    "            # responseq2_plotting = picked.loc[picked['nu']<=np.max(nus)]\n",
    "        except ValueError:\n",
    "            print(\"ValueError: no data points\")\n",
    "        axs[0].plot(responseq2_plotting['nu'],responseq2_plotting[\"RL\"],label=\"Fortran RL\", linestyle='dotted',color='black')    \n",
    "        # axs[0].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RL_fortran_qvcenter_nu\"],label=\"Fortran RL\", s=3,color='black')    \n",
    "        axs[0].errorbar(fit['nu'], fit['RL'], yerr = fit['RLerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[0].scatter(fit['nu'], fit['RL'],marker='D',s=6,color='red',label=\"$Q2_{center}:$\"+str(Q2center))\n",
    "        axs[0].set_title(\"Q2:\"+Q2bin_name)\n",
    "        axs[0].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[0].set_ylabel(\"$R_L$\")\n",
    "        axs[0].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[0].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        axs[1].plot(responseq2_plotting['nu'],responseq2_plotting[\"RT\"],label=\"Fortran RT\",linestyle='dotted',color='black')\n",
    "        # axs[1].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RT_fortran_qvcenter_nu\"],label=\"Fortran RT\", s=3,color='black')\n",
    "        axs[1].errorbar(fit['nu'], fit['RT'], yerr = fit['RTerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[1].scatter(fit['nu'], fit['RT'],marker='D',s=6,color='red',label=\"$Q2_{center}:$\"+str(Q2center))\n",
    "        axs[1].set_title(\"Q2:\"+Q2bin_name)\n",
    "        axs[1].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[1].set_ylabel(\"$R_T$\")\n",
    "        axs[1].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[1].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "\n",
    "        # Q2 = qv**2-nu**2\n",
    "        # W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2center\n",
    "\n",
    "        W_peaks = np.array([0.93,1.07,1.23]) \n",
    "        W_colors = ['orangered','forestgreen','royalblue']\n",
    "        # 0.8649, 1.1449, 1.5129\n",
    "        for i in range(len(W_peaks)):\n",
    "            # axs[0].axvline(x=0.025-mass_nucleon+np.sqrt(qvcenter**2+W_peaks[i]**2), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            # axs[1].axvline(x=0.025-mass_nucleon+np.sqrt(qvcenter**2+W_peaks[i]**2), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            axs[0].axvline(x=0.025+(W_peaks[i]**2-mass_nucleon**2+Q2center)/(2*mass_nucleon), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            axs[1].axvline(x=0.025+(W_peaks[i]**2-mass_nucleon**2+Q2center)/(2*mass_nucleon), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            \n",
    "        # axs[0].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(Q2center))\n",
    "        # axs[1].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(Q2center))\n",
    "\n",
    "\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "        # fig.savefig('figs/FitEx_Qv_'+str(qvcenter)+'.png')\n",
    "\n",
    "        axs[2].scatter(fit['nu'],fit['Chi2_DoF'],color='orange',s=10)\n",
    "        axs[2].set_title('$\\chi^2/DoF$')\n",
    "        axs[2].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[2].set_ylabel(\"$\\chi^2/DoF$\")\n",
    "        axs[2].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[2].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "\n",
    "        axs[0].set_xlim(0.0, fit['nu'].max()*1.02)\n",
    "        axs[1].set_xlim(0.0, fit['nu'].max()*1.02)\n",
    "        axs[2].set_xlim(0.0, fit['nu'].max()*1.02)\n",
    "        if qvcenter >= 0.38:\n",
    "            axs[0].set_ylim(np.min([np.min(fit['RL'])*1.02,0]),np.max(fit['RL'])*1.02)\n",
    "            axs[1].set_ylim(np.min([np.min(fit['RT'])*1.02,0]),np.max(fit['RT'])*1.02)\n",
    "            axs[2].set_ylim(0.0,np.max(fit['Chi2_DoF'])*1.02)\n",
    "\n",
    "        axs[0].legend()\n",
    "        axs[1].legend()\n",
    "        axs[2].legend()\n",
    "\n",
    "        plt.tight_layout()  # Optional, for better spacing between subplots\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_columns = [0]\n",
    "print(Q2centers[inspect_columns[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invesiagte the curve fit, q2 bin, plot in W2, bin in W2\n",
    "df[\"Hbc_Sig(GeV)\"]=df[\"bc_q2_w2\"]*df[\"Hcc_Sig(GeV)\"]\n",
    "df[\"Hbc_error(GeV)\"]=df[\"bc_q2_w2\"]*df[\"Hcc_error(GeV)\"]\n",
    "\n",
    "Photon_plotting = pd.read_csv(\"Photon_plotting.csv\")\n",
    "Ryan = pd.read_csv(\"Ryan_bin_centered.csv\")\n",
    "def append_row(df, row):\n",
    "    return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
    "\n",
    "# eq. 28: for theta = 180,\n",
    "# RT = ((E0/(E0+Veff))**2) * ((Q2eff/(2*alpha*Eprime_eff))**2 ) * cross\n",
    "# df_Ryan = df.loc[df['dataSet']==17].copy()\n",
    "# df_Ryan['RT28'] = (\n",
    "#         (df_Ryan['E0']/df_Ryan['Eeff'])**2\n",
    "#     )*(\n",
    "#        (df_Ryan['Q2eff']/(\n",
    "#               2*alpha_fine*df_Ryan['Eprime_eff']\n",
    "#        ))**2 \n",
    "#     )*df_Ryan['cross']/(((0.1973269**2)*1e10))\n",
    "\n",
    "# plot Sheren Alsami's data\n",
    "df_Sheren = pd.read_excel('Sheren_plotting.xlsx')\n",
    "Sheren_q2s = [0.5,0.8,1.25,1.75,2.25,2.75,3.25,3.75]\n",
    "\n",
    "def linear_model(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "# Yamaguchi_qvs = [0.148,0.167,0.205,0.24,0.3]\n",
    "# Jourdan_qvs = [0.3,0.38,0.57]\n",
    "# Barr_qvs = [0.3,0.4,0.55,]\n",
    "# Create a PdfPages object to save plots to a PDF file\n",
    "fit = pd.DataFrame(columns=['W2','nu','RL','RLerr','RT','RTerr','Chi2',\n",
    "                                    'num_points'])\n",
    "# with PdfPages('curve_fit/curve_fit_'+str(qvcenters[inspect_columns])+'.pdf') as pdf:\n",
    "for i in inspect_columns:\n",
    "    with PdfPages('curve_fit/curve_W2fit_q2_'+str(Q2centers[i])+'.pdf') as pdf:\n",
    "        Q2center = Q2centers[i]\n",
    "        Q2center_data = Q2center_datas[i]\n",
    "        qvcenter = qvcenters[i]\n",
    "        # qvcenter_data = Qvcenter_datas[i]\n",
    "        # qv2center = qvcenter**2\n",
    "        Q2bin_name = Q2bin_names[i]\n",
    "        # W2width = W2widths[i]\n",
    "        W2width = W2widths[i]\n",
    "        Exwidth = 0.02\n",
    "        bin_data = df.loc[df['Q2center']==Q2center].copy()\n",
    "        # drop dataset 13, 18, 19, 21\n",
    "\n",
    "\n",
    "        \n",
    "        RLs = []\n",
    "        RLerrs = []\n",
    "        RTs = []\n",
    "        RTerrs = []\n",
    "        nus = []\n",
    "        RxQ2s = []\n",
    "        RxQ2_errs = []\n",
    "        Exs = []\n",
    "        W2s = []\n",
    "\n",
    "        # nu_grid = np.arange(0.0,2.5,nuwidth*2)\n",
    "        # W2_grid = mass_nucleon**2+2*mass_nucleon*nu_grid-Q2center\n",
    "        W2_grid = np.arange(mass_nucleon**2+2*mass_nucleon*0-Q2center,\n",
    "                            mass_nucleon**2+2*mass_nucleon*2.5-Q2center,\n",
    "                            W2width*2)\n",
    "        \n",
    "\n",
    "        \n",
    "        # for nu in nu_grid:\n",
    "        for W2 in W2_grid:\n",
    "        # for Ex in Ex_grid: \n",
    "            nu = (W2 - mass_nucleon**2 + Q2center)/(2*mass_nucleon)\n",
    "            # W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2center\n",
    "\n",
    "            Ex = nu-Q2center/(2*mass_C12)\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            # q3momt_squared = Q2center+nu**2\n",
    "            qv2 = Q2center+nu**2\n",
    "            # Q2 = qvcenter**2-nu**2\n",
    "            # if Ex >= 0.05:\n",
    "            #     width = 0.01\n",
    "            # else:\n",
    "            #     width = 0.01\n",
    "\n",
    "            # picked = bin_data.loc[((Ex-Exwidth)<=df[\"Ex\"]) & (df[\"Ex\"]<=(Ex+Exwidth)) & (0.030<=df[\"Ex\"])]\n",
    "            # picked = bin_data.loc[((nu-nuwidth)<=df[\"nu\"]) & (df[\"nu\"]<=(nu+nuwidth)) & (0.030<=df[\"Ex\"])]\n",
    "            picked = bin_data.loc[(bin_data['W2']>=W2-W2width) & (bin_data['W2']<=W2+W2width)]\n",
    "            # picked = bin_data.loc[((nu-nuwidth)<=bin_data[\"nu\"]) & (bin_data[\"nu\"]<=(nu+nuwidth))]\n",
    "\n",
    "\n",
    "            # picked = picked.drop_duplicates(keep=\"last\")\n",
    "            x = np.array(picked[\"epsilon\"].values)\n",
    "            y = np.array(picked[\"Hbc_Sig(GeV)\"].values)\n",
    "            y_err = np.array(picked[\"Hbc_error(GeV)\"].values)\n",
    "            \n",
    "            if len(y)>2 and (np.max(x)-np.min(x))>=0.2:\n",
    "                if len(y)==2:\n",
    "                    # print(\"len(y)==2\")\n",
    "                    # duplicated_values = np.concatenate([original_values + 0.1 * original_errors,\n",
    "                    #                     original_values - 0.1 * original_errors])\n",
    "                    # duplicated_errors = original_errors * 1.414\n",
    "                    # duplicated_errors = np.repeat(duplicated_errors, 2)  # Repeat each error twice\n",
    "                    x = np.concatenate([x, x])\n",
    "                    y = np.concatenate([y+0.1*y_err, y-0.1*y_err])\n",
    "                    y_err = y_err * 1.414\n",
    "                    y_err = np.concatenate([y_err, y_err])\n",
    "                params, covariance = curve_fit(linear_model, x, y, sigma=y_err, absolute_sigma=True)\n",
    "\n",
    "                a_opt, b_opt = params\n",
    "                a_err, b_err = np.sqrt(np.diag(covariance))\n",
    "                Chi2 = np.sum(np.square((y-linear_model(x,a_opt,b_opt))/y_err))\n",
    "                RL = a_opt/1000\n",
    "                RT = (2*b_opt*Q2center/qv2)/1000\n",
    "                # if RL>=0 and RT>=0:\n",
    "                RLs.append(RL)\n",
    "                RLerr = a_err/1000 \n",
    "                RLerrs.append(RLerr)\n",
    "                RTs.append(RT)\n",
    "                RTerr = (2*b_err*Q2center/qv2)/1000\n",
    "                RTerrs.append(RTerr)\n",
    "                RxQ2s.append( (2*Q2center/qv2)*RL/RT)\n",
    "                RxQ2_err = np.abs ((2*Q2center/qv2)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
    "                RxQ2_errs.append(RxQ2_err)\n",
    "                W2s.append(W2)\n",
    "                nus.append(nu)\n",
    "\n",
    "                # new_row = {'A': 1, 'B': 2, 'C': 3}   \n",
    "                new_row = pd.Series({'W2':W2,'nu':nu,'RL':RL,'RLerr':RLerr,'RT':RT,'RTerr':RTerr,'Chi2':Chi2,\n",
    "                                    'num_points':len(y)})             \n",
    "                fit = append_row(fit,new_row)\n",
    "#____________________________________________________________________________________________________________________\n",
    "                # if nu >= 0.15:\n",
    "                fig = plt.figure(figsize=(10,4))\n",
    "                plt.plot(x,linear_model(x,a_opt,b_opt),color='gray',label = 'y='+str(round(a_opt,3))\n",
    "                        +'*x+'+str(round(b_opt,3))+'\\nRL,RT:'+str(round(RL,3))+','+str(round(RT,3)))\n",
    "                datasets = picked['dataSet'].unique()\n",
    "                            \n",
    "                plt.title('$Q^{2}_{center}$:'+str(Q2center)+'   W2:'+str(round(W2,3))+'   Ex:'+str(round(Ex,3))+'   nu:'+str(round(nu,3))+'    RL,RT error: '+round_sig_3(RLerr)+','+round_sig_3(RTerr)\n",
    "                          +'   $\\chi^2$:'+str(round(Chi2,1))+'   DoF:'+str(len(y)-2) +'   $\\\\frac{\\chi^2}{DoF}$:'+str(round(Chi2/(len(y)-2),1)))\n",
    "\n",
    "                for dataset in datasets:\n",
    "                    picked_dataset = picked.loc[picked['dataSet']==dataset]\n",
    "                    plt.errorbar(picked_dataset['epsilon'],picked_dataset['Hbc_Sig(GeV)'],yerr=picked_dataset['Hbc_error(GeV)'],\n",
    "                                 fmt ='.',capsize=3,markersize='3')\n",
    "                    plt.scatter(picked_dataset['epsilon'],picked_dataset['Hbc_Sig(GeV)'],s=10, label = str(dataset)+' '+dataSet_to_name[dataset])\n",
    "\n",
    "                # plt.scatter(x,y,s=1)\n",
    "                plt.xlabel('epsilon')\n",
    "                plt.ylabel('Hbc')\n",
    "                plt.legend()\n",
    "                pdf.savefig(fig)\n",
    "#____________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "        # fit = pd.DataFrame({'nu':nus,'RL':RLs,'RLerr':RLerrs,'RT':RTs,'RTerr':RTerrs})\n",
    "        fit['Chi2_DoF']=fit['Chi2']/(fit['num_points']-2)\n",
    "        # fit = fit.loc[fit['RL']>=-0.08]\n",
    "        # drop thelargest RL errors\n",
    "        # for drop_err in range(4):\n",
    "        #     fit = fit.drop(fit['RLerr'].idxmax())\n",
    "\n",
    "        # fit = fit.drop(fit['RLerr'].idxmax())\n",
    "\n",
    "        # fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # 1 row, 3 columns\n",
    "        # fig, axs = plt.subplots(1, 2, figsize=(10, 5))  # 1 row, 2 columns\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(10, 15))  # 3 row, 1 columns\n",
    "\n",
    "\n",
    "        tick_spacing = 0.05\n",
    "\n",
    "\n",
    "        try:\n",
    "            responseq2_plotting = Q2center_data.loc[(Q2center_data['W2']<=fit['W2'].max())]\n",
    "            # responseq2_plotting = qvcenter_data.loc[qvcenter_data['nu']<=photon_data['nu']]\n",
    "            # responseq2_plotting = picked.loc[picked['nu']<=np.max(nus)]\n",
    "        except ValueError:\n",
    "            print(\"ValueError: no data points\")\n",
    "        axs[0].plot(responseq2_plotting['W2'],responseq2_plotting[\"RL\"],label=\"Fortran RL\", linestyle='dotted',color='black')    \n",
    "        # axs[0].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RL_fortran_qvcenter_nu\"],label=\"Fortran RL\", s=3,color='black')    \n",
    "        axs[0].errorbar(fit['W2'], fit['RL'], yerr = fit['RLerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[0].scatter(fit['W2'], fit['RL'],marker='D',s=6,color='red',label=\"$Q2_{center}:$\"+str(Q2center))\n",
    "        axs[0].set_title(\"Q2:\"+Q2bin_name)\n",
    "        axs[0].set_xlabel(\"$W^2 (GeV)$\")\n",
    "        axs[0].set_ylabel(\"$R_L$\")\n",
    "        axs[0].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[0].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        axs[1].plot(responseq2_plotting['W2'],responseq2_plotting[\"RT\"],label=\"Fortran RT\",linestyle='dotted',color='black')\n",
    "        # axs[1].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RT_fortran_qvcenter_nu\"],label=\"Fortran RT\", s=3,color='black')\n",
    "        axs[1].errorbar(fit['W2'], fit['RT'], yerr = fit['RTerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[1].scatter(fit['W2'], fit['RT'],marker='D',s=6,color='red',label=\"$Q2_{center}:$\"+str(Q2center))\n",
    "        axs[1].set_title(\"Q2:\"+Q2bin_name)\n",
    "        axs[1].set_xlabel(\"$W^2 (GeV)$\")\n",
    "        axs[1].set_ylabel(\"$R_T$\")\n",
    "        axs[1].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[1].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "\n",
    "        if Q2center in Sheren_q2s:\n",
    "            Sheren = df_Sheren.loc[df_Sheren['Q2']==Q2center]\n",
    "            axs[0].errorbar(Sheren['W2'], Sheren['RL']*12, yerr = Sheren['RLerr']*12, color='lightblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[0].scatter(Sheren['W2'], Sheren['RL']*12,marker='D',s=6,color='blue',label=\"Sheren\")\n",
    "            axs[1].errorbar(Sheren['W2'], Sheren['RT']*12, yerr = Sheren['RTerr']*12, color='lightblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Sheren['W2'], Sheren['RT']*12,marker='D',s=6,color='blue',label=\"Sheren\")\n",
    "            \n",
    "\n",
    "\n",
    "        # Q2 = qv**2-nu**2\n",
    "        # W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2center\n",
    "\n",
    "        W_peaks = np.array([0.93,1.07,1.23]) \n",
    "        W_colors = ['orangered','forestgreen','royalblue']\n",
    "        # 0.8649, 1.1449, 1.5129\n",
    "        for i in range(len(W_peaks)):\n",
    "            # axs[0].axvline(x=0.025+(W_peaks[i]**2-mass_nucleon**2+Q2center)/(2*mass_nucleon), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            # axs[1].axvline(x=0.025+(W_peaks[i]**2-mass_nucleon**2+Q2center)/(2*mass_nucleon), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            axs[0].axvline(x=W_peaks[i]**2, color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            axs[1].axvline(x=W_peaks[i]**2, color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            \n",
    "        # axs[0].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(Q2center))\n",
    "        # axs[1].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(Q2center))\n",
    "\n",
    "\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "        # fig.savefig('figs/FitEx_Qv_'+str(qvcenter)+'.png')\n",
    "\n",
    "        axs[2].scatter(fit['W2'],fit['Chi2_DoF'],color='orange',s=10)\n",
    "        axs[2].set_title('$\\chi^2/DoF$')\n",
    "        axs[2].set_xlabel(\"W^2 (GeV)$\")\n",
    "        axs[2].set_ylabel(\"$\\chi^2/DoF$\")\n",
    "        axs[2].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[2].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "\n",
    "        axs[0].set_xlim(fit['W2'].min()*0.98, fit['W2'].max()*1.02)\n",
    "        axs[1].set_xlim(fit['W2'].min()*0.98, fit['W2'].max()*1.02)\n",
    "        axs[2].set_xlim(fit['W2'].min()*0.98, fit['W2'].max()*1.02)\n",
    "        if qvcenter >= 0.38:\n",
    "            axs[0].set_ylim(np.min([np.min(fit['RL'])*1.02,0]),np.max(fit['RL'])*1.02)\n",
    "            axs[1].set_ylim(np.min([np.min(fit['RT'])*1.02,0]),np.max(fit['RT'])*1.02)\n",
    "            axs[2].set_ylim(0.0,np.max(fit['Chi2_DoF'])*1.02)\n",
    "\n",
    "        axs[0].legend()\n",
    "        axs[1].legend()\n",
    "        axs[2].legend()\n",
    "\n",
    "        plt.tight_layout()  # Optional, for better spacing between subplots\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce RL, RT plots for all the qv bin, in nu\n",
    "df[\"Hbc_Sig(GeV)\"]=df[\"bc_qv_nu\"]*df[\"Hcc_Sig(GeV)\"]\n",
    "df[\"Hbc_error(GeV)\"]=df[\"bc_qv_nu\"]*df[\"Hcc_error(GeV)\"]\n",
    "\n",
    "Photon_plotting = pd.read_csv(\"Photon_plotting.csv\")\n",
    "Ryan = pd.read_csv(\"Ryan_bin_centered.csv\")\n",
    "def append_row(df, row):\n",
    "    return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
    "\n",
    "# eq. 28: for theta = 180,\n",
    "# RT = ((E0/(E0+Veff))**2) * ((Q2eff/(2*alpha*Eprime_eff))**2 ) * cross\n",
    "df_Ryan = df.loc[df['dataSet']==17].copy()\n",
    "df_Ryan['RT28'] = (\n",
    "        (df_Ryan['E0']/df_Ryan['Eeff'])**2\n",
    "    )*(\n",
    "       (df_Ryan['Q2eff']/(\n",
    "              2*alpha_fine*df_Ryan['Eprime_eff']\n",
    "       ))**2 \n",
    "    )*df_Ryan['cross']/(((0.1973269**2)*1e10))\n",
    "\n",
    "\n",
    "def linear_model(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "Yamaguchi_qvs = [0.148,0.167,0.205,0.24,0.3]\n",
    "Jourdan_qvs = [0.3,0.38,0.57]\n",
    "Barr_qvs = [0.3,0.4,0.55,]\n",
    "SF_FSI_qvs = [0.148,0.167,0.205,0.24,0.3,0.38,0.475,0.57,0.649,0.756]\n",
    "# Create a PdfPages object to save plots to a PDF file\n",
    "\n",
    "# with PdfPages('curve_fit/curve_fit_'+str(qvcenters[inspect_columns])+'.pdf') as pdf:\n",
    "with PdfPages('figures/RLRT_Qvbin_nu.pdf') as pdf:\n",
    "    for i in range(len(qvcenters)):\n",
    "        qvcenter = qvcenters[i]\n",
    "        qvcenter_data = Qvcenter_datas[i]\n",
    "        qv2center = qvcenter**2\n",
    "        qvbin_name = qvbin_names[i]\n",
    "        W2width = W2widths[i]\n",
    "        Exwidth = 0.02\n",
    "        bin_data = df.loc[df['qvcenter']==qvcenter].copy()\n",
    "        # drop dataset 13, 18, 19, 21\n",
    "        fit = pd.DataFrame(columns=['nu','RL','RLerr','RT','RTerr','Chi2','num_points'])\n",
    "        nuwidth = nuwidths[i]\n",
    "\n",
    "\n",
    "        \n",
    "        RLs = []\n",
    "        RLerrs = []\n",
    "        RTs = []\n",
    "        RTerrs = []\n",
    "        nus = []\n",
    "        RxQ2s = []\n",
    "        RxQ2_errs = []\n",
    "        Exs = []\n",
    "        Ex_grid = np.arange(0.0,0.5,0.01)\n",
    "\n",
    "        # formulate 0 < nu < q3\n",
    "        nu_grid = np.arange(0.0,qvcenter,nuwidth*2)\n",
    "\n",
    "        \n",
    "        for nu in nu_grid:\n",
    "        # for Ex in Ex_grid:\n",
    "            Ex = nu-(qvcenter**2-nu**2)/(2*mass_C12)\n",
    "            if Ex < 0:\n",
    "                continue\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            # qv2 = Q2center+nu**2\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            Q2 = qvcenter**2-nu**2\n",
    "            W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2\n",
    "\n",
    "            picked = bin_data.loc[((nu-nuwidth)<=bin_data[\"nu\"]) & (bin_data[\"nu\"]<=(nu+nuwidth))]\n",
    "\n",
    "\n",
    "\n",
    "            # picked = picked.drop_duplicates(keep=\"last\")\n",
    "            x = np.array(picked[\"epsilon\"].values)\n",
    "            y = np.array(picked[\"Hbc_Sig(GeV)\"].values)\n",
    "            y_err = np.array(picked[\"Hbc_error(GeV)\"].values)\n",
    "            \n",
    "            if len(y)>2 and (np.max(x)-np.min(x))>=0.25:\n",
    "                if len(y)==2:\n",
    "                    x = np.concatenate([x, x])\n",
    "                    y = np.concatenate([y+0.1*y_err, y-0.1*y_err])\n",
    "                    y_err = y_err * 1.414\n",
    "                    y_err = np.concatenate([y_err, y_err])\n",
    "\n",
    "                params, covariance = curve_fit(linear_model, x, y, sigma=y_err, absolute_sigma=True)\n",
    "\n",
    "                a_opt, b_opt = params\n",
    "                a_err, b_err = np.sqrt(np.diag(covariance))\n",
    "                Chi2 = np.sum(np.square((y-linear_model(x,a_opt,b_opt))/y_err))\n",
    "                RL = a_opt/1000\n",
    "                RT = (2*b_opt*Q2/qv2center)/1000\n",
    "                # if RL>=0 and RT>=0:\n",
    "                RLs.append(RL)\n",
    "                RLerr = a_err/1000 \n",
    "                RLerrs.append(RLerr)\n",
    "                RTs.append(RT)\n",
    "                RTerr = (2*b_err*Q2/qv2center)/1000\n",
    "                RTerrs.append(RTerr)\n",
    "                RxQ2s.append( (2*Q2/qv2center)*RL/RT)\n",
    "                RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
    "                RxQ2_errs.append(RxQ2_err)\n",
    "                # W2s.append(W2)\n",
    "                nus.append(nu)\n",
    "                new_row = pd.Series({'nu':nu,'RL':RL,'RLerr':RLerr,'RT':RT,'RTerr':RTerr,'Chi2':Chi2,\n",
    "                                    'num_points':len(y)})             \n",
    "                fit = append_row(fit,new_row)\n",
    "\n",
    "\n",
    "        # fit = pd.DataFrame({'nu':nus,'RL':RLs,'RLerr':RLerrs,'RT':RTs,'RTerr':RTerrs})\n",
    "        fit['Chi2_DoF']=fit['Chi2']/(fit['num_points']-2)\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(8, 12))  # 3 row, 1 columns\n",
    "\n",
    "\n",
    "        tick_spacing = 0.05\n",
    "\n",
    "        # photo-production data\n",
    "        photon_index = (Photon_plotting['qv'] - qvcenter).abs().idxmin()\n",
    "        photon_data = Photon_plotting.loc[photon_index]\n",
    "\n",
    "        try:\n",
    "            responseq2_plotting = qvcenter_data.loc[qvcenter_data['nu']<=qvcenter]\n",
    "            # responseq2_plotting = qvcenter_data.loc[qvcenter_data['nu']<=photon_data['nu']]\n",
    "            # responseq2_plotting = picked.loc[picked['nu']<=np.max(nus)]\n",
    "        except ValueError:\n",
    "            print(\"ValueError: no data points\")\n",
    "        axs[0].plot(responseq2_plotting['nu'],responseq2_plotting[\"RL\"],color='dimgray',label=\"RL Total Christy-Bodek Fit\", linestyle='solid')    \n",
    "        axs[0].plot(responseq2_plotting['nu'],responseq2_plotting[\"RLQE\"],color='sienna',label=\"RL QE Christy-Bodek Fit\", linestyle='dashed')    \n",
    "        # axs[0].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RL_fortran_qvcenter_nu\"],label=\"Fortran RL\", s=3,color='black')    \n",
    "        axs[0].errorbar(fit['nu'], fit['RL'], yerr = fit['RLerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[0].scatter(fit['nu'], fit['RL'],marker='D',s=6,color='red',label='RL our fit')\n",
    "        axs[0].set_title(\"$\\mathbf{q}=$\"+str(qvcenter)+' bin:'+qvbin_name)\n",
    "        axs[0].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[0].set_ylabel(\"$R_L$\")\n",
    "        axs[0].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[0].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        axs[1].plot(responseq2_plotting['nu'],responseq2_plotting[\"RT\"],color='dimgray',label=\"RT Total Christy-Bodek Fit\",linestyle='solid')\n",
    "        axs[1].plot(responseq2_plotting['nu'],responseq2_plotting[\"RTQE\"],color='sienna',label=\"RT QE Christy-Bodek Fit\",linestyle='dashed')\n",
    "        # axs[1].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RT_fortran_qvcenter_nu\"],label=\"Fortran RT\", s=3,color='black')\n",
    "        axs[1].errorbar(fit['nu'], fit['RT'], yerr = fit['RTerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[1].scatter(fit['nu'], fit['RT'],marker='D',s=6,color='red',label='RT our fit')\n",
    "        axs[1].set_title(\"$\\mathbf{q}=$\"+str(qvcenter)+' bin:'+qvbin_name)\n",
    "        axs[1].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[1].set_ylabel(\"$R_T$\")\n",
    "        axs[1].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[1].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        # photon-production data\n",
    "        axs[1].scatter(photon_data['nu'],photon_data[\"RT\"],marker='^',s=30,color='lime',label=\"RT Photo-production\")\n",
    "\n",
    "        if qvcenter in Ryan['qvcenter'].unique():\n",
    "            # Ryan_data = Ryan.loc[Ryan['qvcenter']==qvcenter]\n",
    "            # axs[1].errorbar(Ryan_data['nu'],Ryan_data[\"RT_bc\"], yerr = Ryan_data[\"RTerr_bc\"], color='plum', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[1].scatter(Ryan_data['nu'],Ryan_data[\"RT_bc\"],marker='D',s=6,color='plum',label=\"Ryan bin_centered\")\n",
    "\n",
    "            Ryan_data = df_Ryan.loc[df_Ryan['qvcenter']==qvcenter]\n",
    "            axs[1].scatter(Ryan_data['nu'],Ryan_data[\"RT28\"],marker='D',s=6,color='plum',label=\"RT Ryan\")\n",
    "\n",
    "        \n",
    "        if qvcenter in Jourdan_qvs:\n",
    "            Jourdan_data = pd.read_excel('Jourdan_RL_RT_plots.xlsx')\n",
    "            Jourdan_data = Jourdan_data.loc[Jourdan_data['Q']==qvcenter]\n",
    "            axs[0].errorbar(Jourdan_data['nu'],Jourdan_data[\"RL\"], yerr = Jourdan_data[\"Error(RL)\"], color='darkred', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[0].scatter(Jourdan_data['nu'],Jourdan_data[\"RL\"],marker='D',s=6,color='darkred',label=\"RL Jourdan\")\n",
    "            axs[1].errorbar(Jourdan_data['nu'],Jourdan_data[\"RT\"], yerr = Jourdan_data[\"Error(RT)\"], color='darkred', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Jourdan_data['nu'],Jourdan_data[\"RT\"],marker='D',s=6,color='darkred',label=\"RT Jourdan\")\n",
    "        \n",
    "            # plot barreau along with Ryan\n",
    "            \n",
    "            if qvcenter == 0.3:\n",
    "                bar_qv = 0.3    \n",
    "            if qvcenter == 0.38:\n",
    "                bar_qv = 0.4\n",
    "            elif qvcenter == 0.57:\n",
    "                bar_qv = 0.55\n",
    "            \n",
    "            Bar_RL = pd.read_excel('Barreau_plotting.xlsx',sheet_name='RL_qv_'+str(bar_qv))\n",
    "            Bar_RL.columns = ['qv','nu','RL','RLerr']\n",
    "            axs[0].errorbar(Bar_RL['nu'],Bar_RL[\"RL\"], yerr = Bar_RL[\"RLerr\"], color='steelblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[0].scatter(Bar_RL['nu'],Bar_RL[\"RL\"],marker='D',s=6,color='blue',label=\"RL Barreau $\\mathbf{q}=$\"+str(bar_qv))\n",
    "            Bar_RT = pd.read_excel('Barreau_plotting.xlsx',sheet_name='RT_qv_'+str(bar_qv))\n",
    "            Bar_RT.columns = ['qv','nu','RT','RTerr']\n",
    "            axs[1].errorbar(Bar_RT['nu'],Bar_RT[\"RT\"], yerr = Bar_RT[\"RTerr\"], color='steelblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Bar_RT['nu'],Bar_RT[\"RT\"],marker='D',s=6,color='blue',label=\"RT Barreau \\mathbf{q}=\"+str(bar_qv))\n",
    "        Yam_RLmax = 0\n",
    "        Yam_RTmax = 0\n",
    "        if qvcenter in Yamaguchi_qvs:\n",
    "            Yam_data = pd.read_excel('Yamaguchi_plotting.xlsx',sheet_name='qv_'+str(qvcenter))\n",
    "            # Yam_data['nu_RL'] = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Yam_data['EX_RL'])\n",
    "            # Yam_data['nu_RT'] = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Yam_data['EX_RT'])\n",
    "            # Ex = nu-(qv^2-nu^2)/(2M)\n",
    "            # nu = - M + sqrt(M^2 + qv^2 + 2M*Ex)\n",
    "            # solve quadratic equation\n",
    "            \n",
    "            # axs[0].errorbar(Yam_data['nu_RL'],Yam_data[\"RL\"], yerr = Yam_data[\"RL\"]*0.03, color='lightpink', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[0].scatter(Yam_data['nu_RL'],Yam_data[\"RL\"],marker='D',s=6,color='skyblue',label=\"RL Yamaguchi\")\n",
    "            # axs[1].errorbar(Yam_data['nu_RT'],Yam_data[\"RT\"], yerr = Yam_data[\"RT\"]*0.03, color='lightpink', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Yam_data['nu_RT'],Yam_data[\"RT\"],marker='D',s=6,color='skyblue',label=\"RT Yamaguchi\")\n",
    "            Yam_RLmax = Yam_data[\"RL\"].max()\n",
    "            Yam_RTmax = Yam_data[\"RT\"].max()\n",
    "            \n",
    "        # goldemberg\n",
    "        if qvcenter == 0.1: \n",
    "            Goldem_data = pd.read_csv('Goldemberger_180.csv')\n",
    "            axs[1].errorbar(Goldem_data['nu'],Goldem_data[\"RT\"], yerr = Goldem_data[\"error\"], color='skyblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Goldem_data['nu'],Goldem_data[\"RT\"],marker='D',s=6,color='blue',label=\"RT Goldemberg\")\n",
    "        # NuWRo\n",
    "        if qvcenter in SF_FSI_qvs:\n",
    "            qvcenter_MeV = int(qvcenter*1000)\n",
    "            df_SF = pd.read_csv('SF_FSI/Resp_FSI_12C_'+str(qvcenter_MeV)+'_SF.txt',delim_whitespace=True,header=None)\n",
    "            df_SF.columns = ['nu','RL','RT']\n",
    "            axs[0].plot(df_SF['nu']/1000,df_SF['RL'],label='RL QE NuWRo-SF-FSI',linestyle='dashed',color='olive')\n",
    "            axs[1].plot(df_SF['nu']/1000,df_SF['RT'],label='RT QE NuWRo-SF-FSI',linestyle='dashed',color='olive')\n",
    "\n",
    "            \n",
    "\n",
    "        # W2_peaks = np.array([0.93,1.07,1.23])\n",
    "        W_peaks = np.array([0.93,1.07,1.23]) \n",
    "        W_colors = ['orangered','forestgreen','royalblue']\n",
    "        # 0.8649, 1.1449, 1.5129\n",
    "        for i in range(len(W_peaks)):\n",
    "            axs[0].axvline(x=0.025-mass_nucleon+np.sqrt(qvcenter**2+W_peaks[i]**2), color = W_colors[i], linestyle='dotted',label='$W=$'+str(W_peaks[i]))\n",
    "            axs[1].axvline(x=0.025-mass_nucleon+np.sqrt(qvcenter**2+W_peaks[i]**2), color = W_colors[i], linestyle='dotted',label='$W=$'+str(W_peaks[i]))\n",
    "        axs[0].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='$\\\\nu=$'+str(qvcenter))\n",
    "        axs[1].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='$\\\\nu=$'+str(qvcenter))\n",
    "\n",
    "\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "        # fig.savefig('figs/FitEx_Qv_'+str(qvcenter)+'.png')\n",
    "\n",
    "        axs[2].scatter(fit['nu'],fit['Chi2_DoF'],color='orange',s=10,label='$\\chi^2/DoF$')\n",
    "        axs[2].set_title('$\\chi^2/DoF$')\n",
    "        axs[2].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[2].set_ylabel(\"$\\chi^2/DoF$\")\n",
    "        axs[2].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[2].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "        totalChi2 = np.sum(fit['Chi2'])\n",
    "\n",
    "\n",
    "        axs[0].set_xlim(0.0, qvcenter*1.01)\n",
    "        axs[1].set_xlim(0.0, qvcenter*1.01)\n",
    "        axs[2].set_xlim(0.0, qvcenter*1.01)\n",
    "        if qvcenter == 0.1:\n",
    "            axs[0].set_ylim(0.0,None)\n",
    "            axs[1].set_ylim(0.0,None)\n",
    "        elif qvcenter in Yamaguchi_qvs:\n",
    "\n",
    "            RLmax = np.max(np.array(Yam_RLmax,fit['RL'].max()))\n",
    "            axs[0].set_ylim(0.0,RLmax+0.005)\n",
    "            RTmaxes = np.array([Yam_RTmax,fit['RT'].max(),photon_data['RT'].max()])\n",
    "            RTmax = np.max(RTmaxes)\n",
    "            axs[1].set_ylim(0.0,RTmax+0.005)\n",
    "        elif qvcenter == 1.302:\n",
    "            axs[0].set_ylim(0.0,None)\n",
    "            axs[1].set_ylim(0.0,None)\n",
    "        else:\n",
    "            axs[0].set_ylim(0,fit['RL'].max()+0.005)\n",
    "            RTmax = np.max([fit['RT'].max(),photon_data['RT'].max()])\n",
    "            axs[1].set_ylim(0,RTmax+0.005)\n",
    "            # axs[0].set_ylim(np.min([np.min(fit['RL'])*1.02,0]),np.max(fit['RL'],photon_data['RT'].max())*1.01)\n",
    "            # axs[1].set_ylim(np.min([np.min(fit['RT'])*1.02,0]),np.max(fit['RT'],photon_data['RT'].max())*1.01)\n",
    "        # axs[2].set_ylim(0.0,fit['Chi2_DoF'].max()*1.01)\n",
    "        # if qvcenter >= 0.38:\n",
    "        #     axs[0].set_ylim(np.min([np.min(fit['RL'])*1.02,0]),np.max(fit['RL'])*1.02)\n",
    "        #     axs[1].set_ylim(np.min([np.min(fit['RT'])*1.02,0]),np.max(fit['RT'])*1.02)\n",
    "        #     axs[2].set_ylim(0.0,np.max(fit['Chi2_DoF'])*1.02)\n",
    "\n",
    "        axs[0].legend()\n",
    "        axs[1].legend()\n",
    "        axs[2].legend()\n",
    "\n",
    "        plt.tight_layout()  # Optional, for better spacing between subplots\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce RL, RT plots for all the q2 bin, in nu\n",
    "\n",
    "# invesiagte the curve fit, q2 bin\n",
    "df[\"Hbc_Sig(GeV)\"]=df[\"bc_q2_nu\"]*df[\"Hcc_Sig(GeV)\"]\n",
    "df[\"Hbc_error(GeV)\"]=df[\"bc_q2_nu\"]*df[\"Hcc_error(GeV)\"]\n",
    "# df[\"Hbc_Sig(GeV)\"]=df[\"Hcc_Sig(GeV)\"]\n",
    "# df[\"Hbc_error(GeV)\"]=df[\"Hcc_error(GeV)\"]\n",
    "\n",
    "Photon_plotting = pd.read_csv(\"Photon_plotting.csv\")\n",
    "Ryan = pd.read_csv(\"Ryan_bin_centered.csv\")\n",
    "def append_row(df, row):\n",
    "    return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
    "\n",
    "# eq. 28: for theta = 180,\n",
    "# RT = ((E0/(E0+Veff))**2) * ((Q2eff/(2*alpha*Eprime_eff))**2 ) * cross\n",
    "# df_Ryan = df.loc[df['dataSet']==17].copy()\n",
    "# df_Ryan['RT28'] = (\n",
    "#         (df_Ryan['E0']/df_Ryan['Eeff'])**2\n",
    "#     )*(\n",
    "#        (df_Ryan['Q2eff']/(\n",
    "#               2*alpha_fine*df_Ryan['Eprime_eff']\n",
    "#        ))**2 \n",
    "#     )*df_Ryan['cross']/(((0.1973269**2)*1e10))\n",
    "\n",
    "\n",
    "def linear_model(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "# Yamaguchi_qvs = [0.148,0.167,0.205,0.24,0.3]\n",
    "# Jourdan_qvs = [0.3,0.38,0.57]\n",
    "# Barr_qvs = [0.3,0.4,0.55,]\n",
    "# Create a PdfPages object to save plots to a PDF file\n",
    "\n",
    "# with PdfPages('curve_fit/curve_fit_'+str(qvcenters[inspect_columns])+'.pdf') as pdf:\n",
    "with PdfPages('figures/RLRT_Q2bin_nu.pdf') as pdf:\n",
    "    for i in range(len(Q2centers)):\n",
    "        Q2center = Q2centers[i]\n",
    "        Q2center_data = Q2center_datas[i]\n",
    "        qvcenter = qvcenters[i]\n",
    "        # qvcenter_data = Qvcenter_datas[i]\n",
    "        # qv2center = qvcenter**2\n",
    "        Q2bin_name = Q2bin_names[i]\n",
    "        W2width = W2widths[i]\n",
    "        Exwidth = 0.02\n",
    "        bin_data = df.loc[df['Q2center']==Q2center].copy()\n",
    "        # drop dataset 13, 18, 19, 21\n",
    "        fit = pd.DataFrame(columns=['nu','RL','RLerr','RT','RTerr','Chi2','num_points'])\n",
    "\n",
    "        nuwidth=nuwidths[i]\n",
    "        RLs = []\n",
    "        RLerrs = []\n",
    "        RTs = []\n",
    "        RTerrs = []\n",
    "        nus = []\n",
    "        RxQ2s = []\n",
    "        RxQ2_errs = []\n",
    "        Exs = []\n",
    "\n",
    "        # formulate 0 < nu < q3\n",
    "        nu_grid = np.arange(0.0,2.5,nuwidth*2)\n",
    "\n",
    "        \n",
    "        for nu in nu_grid:\n",
    "        # for Ex in Ex_grid:\n",
    "            Ex = nu-Q2center/(2*mass_C12)\n",
    "            if Ex < 0:\n",
    "                continue\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            # q3momt_squared = Q2center+nu**2\n",
    "            qv2 = Q2center+nu**2\n",
    "            # Q2 = qvcenter**2-nu**2\n",
    "            W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2center\n",
    "            # if Ex >= 0.05:\n",
    "            #     width = 0.01\n",
    "            # else:\n",
    "            #     width = 0.01\n",
    "\n",
    "            # picked = bin_data.loc[(W2<=bin_data[\"W2\"]) & (bin_data[\"W2\"]<=(W2+2*W2width)) & (bin_data['Ex']>0.025)]\n",
    "            # picked = bin_data.loc[((Ex-Exwidth)<=df[\"Ex\"]) & (df[\"Ex\"]<=(Ex+Exwidth)) & (0.030<=df[\"Ex\"])]\n",
    "            # picked = bin_data.loc[((nu-nuwidth)<=df[\"nu\"]) & (df[\"nu\"]<=(nu+nuwidth)) & (0.030<=df[\"Ex\"])]\n",
    "            picked = bin_data.loc[((nu-nuwidth)<=bin_data[\"nu\"]) & (bin_data[\"nu\"]<=(nu+nuwidth))]\n",
    "\n",
    "\n",
    "            # picked = picked.drop_duplicates(keep=\"last\")\n",
    "            x = np.array(picked[\"epsilon\"].values)\n",
    "            y = np.array(picked[\"Hbc_Sig(GeV)\"].values)\n",
    "            y_err = np.array(picked[\"Hbc_error(GeV)\"].values)\n",
    "            \n",
    "            if len(y)>=2 and (np.max(x)-np.min(x))>=0.2:\n",
    "                if len(y)==2:\n",
    "                    # print(\"len(y)==2\")\n",
    "                    # duplicated_values = np.concatenate([original_values + 0.1 * original_errors,\n",
    "                    #                     original_values - 0.1 * original_errors])\n",
    "                    # duplicated_errors = original_errors * 1.414\n",
    "                    # duplicated_errors = np.repeat(duplicated_errors, 2)  # Repeat each error twice\n",
    "                    x = np.concatenate([x, x])\n",
    "                    y = np.concatenate([y+0.1*y_err, y-0.1*y_err])\n",
    "                    y_err = y_err * 1.414\n",
    "                    y_err = np.concatenate([y_err, y_err])\n",
    "                params, covariance = curve_fit(linear_model, x, y, sigma=y_err, absolute_sigma=True)\n",
    "                a_opt, b_opt = params\n",
    "                a_err, b_err = np.sqrt(np.diag(covariance))\n",
    "                Chi2 = np.sum(np.square((y-linear_model(x,a_opt,b_opt))/y_err))\n",
    "                RL = a_opt/1000\n",
    "                RT = (2*b_opt*Q2center/qv2)/1000\n",
    "                # if RL>=0 and RT>=0:\n",
    "                RLs.append(RL)\n",
    "                RLerr = a_err/1000 \n",
    "                RLerrs.append(RLerr)\n",
    "                RTs.append(RT)\n",
    "                RTerr = (2*b_err*Q2center/qv2)/1000\n",
    "                RTerrs.append(RTerr)\n",
    "                RxQ2s.append( (2*Q2center/qv2)*RL/RT)\n",
    "                RxQ2_err = np.abs ((2*Q2center/qv2)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
    "                RxQ2_errs.append(RxQ2_err)\n",
    "                # W2s.append(W2)\n",
    "                nus.append(nu)\n",
    "\n",
    "                # new_row = {'A': 1, 'B': 2, 'C': 3}   \n",
    "                new_row = pd.Series({'nu':nu,'RL':RL,'RLerr':RLerr,'RT':RT,'RTerr':RTerr,'Chi2':Chi2,\n",
    "                                    'num_points':len(y)})             \n",
    "                fit = append_row(fit,new_row)\n",
    "\n",
    "        # fit = pd.DataFrame({'nu':nus,'RL':RLs,'RLerr':RLerrs,'RT':RTs,'RTerr':RTerrs})\n",
    "        fit['Chi2_DoF']=fit['Chi2']/(fit['num_points']-2)\n",
    "\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(8, 12))  # 3 row, 1 columns\n",
    "\n",
    "\n",
    "        tick_spacing = 0.05\n",
    "\n",
    "\n",
    "        try:\n",
    "            responseq2_plotting = Q2center_data.loc[Q2center_data['nu']<=fit['nu'].max()]\n",
    "            # responseq2_plotting = qvcenter_data.loc[qvcenter_data['nu']<=photon_data['nu']]\n",
    "            # responseq2_plotting = picked.loc[picked['nu']<=np.max(nus)]\n",
    "        except ValueError:\n",
    "            print(\"ValueError: no data points\")\n",
    "        axs[0].plot(responseq2_plotting['nu'],responseq2_plotting[\"RL\"],label=\"Fortran RL\", linestyle='dotted',color='black')    \n",
    "        # axs[0].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RL_fortran_qvcenter_nu\"],label=\"Fortran RL\", s=3,color='black')    \n",
    "        axs[0].errorbar(fit['nu'], fit['RL'], yerr = fit['RLerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[0].scatter(fit['nu'], fit['RL'],marker='D',s=6,color='red',label=\"$Q2_{center}:$\"+str(Q2center))\n",
    "        axs[0].set_title(\"Q2:\"+Q2bin_name)\n",
    "        axs[0].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[0].set_ylabel(\"$R_L$\")\n",
    "        axs[0].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[0].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        axs[1].plot(responseq2_plotting['nu'],responseq2_plotting[\"RT\"],label=\"Fortran RT\",linestyle='dotted',color='black')\n",
    "        # axs[1].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RT_fortran_qvcenter_nu\"],label=\"Fortran RT\", s=3,color='black')\n",
    "        axs[1].errorbar(fit['nu'], fit['RT'], yerr = fit['RTerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[1].scatter(fit['nu'], fit['RT'],marker='D',s=6,color='red',label=\"$Q2_{center}:$\"+str(Q2center))\n",
    "        axs[1].set_title(\"Q2:\"+Q2bin_name)\n",
    "        axs[1].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[1].set_ylabel(\"$R_T$\")\n",
    "        axs[1].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[1].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "\n",
    "        # Q2 = qv**2-nu**2\n",
    "        # W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2center\n",
    "\n",
    "        W_peaks = np.array([0.93,1.07,1.23]) \n",
    "        W_colors = ['orangered','forestgreen','royalblue']\n",
    "        # 0.8649, 1.1449, 1.5129\n",
    "        for i in range(len(W_peaks)):\n",
    "            # axs[0].axvline(x=0.025-mass_nucleon+np.sqrt(qvcenter**2+W_peaks[i]**2), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            # axs[1].axvline(x=0.025-mass_nucleon+np.sqrt(qvcenter**2+W_peaks[i]**2), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            axs[0].axvline(x=0.025+(W_peaks[i]**2-mass_nucleon**2+Q2center)/(2*mass_nucleon), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            axs[1].axvline(x=0.025+(W_peaks[i]**2-mass_nucleon**2+Q2center)/(2*mass_nucleon), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            \n",
    "        # axs[0].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(Q2center))\n",
    "        # axs[1].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(Q2center))\n",
    "\n",
    "\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "        # fig.savefig('figs/FitEx_Qv_'+str(qvcenter)+'.png')\n",
    "\n",
    "        axs[2].scatter(fit['nu'],fit['Chi2_DoF'],color='orange',s=10,label='$\\chi^2/DoF$')\n",
    "        axs[2].set_title('$\\chi^2/DoF$')\n",
    "        axs[2].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[2].set_ylabel(\"$\\chi^2/DoF$\")\n",
    "        axs[2].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[2].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "\n",
    "        axs[0].set_xlim(0.0, fit['nu'].max()*1.02)\n",
    "        axs[1].set_xlim(0.0, fit['nu'].max()*1.02)\n",
    "        axs[2].set_xlim(0.0, fit['nu'].max()*1.02)\n",
    "        if qvcenter >= 0.38:\n",
    "            axs[0].set_ylim(np.min([np.min(fit['RL'])*1.02,0]),np.max(fit['RL'])*1.02)\n",
    "            axs[1].set_ylim(np.min([np.min(fit['RT'])*1.02,0]),np.max(fit['RT'])*1.02)\n",
    "            axs[2].set_ylim(0.0,np.max(fit['Chi2_DoF'])*1.02)\n",
    "\n",
    "        axs[0].legend()\n",
    "        axs[1].legend()\n",
    "        axs[2].legend()\n",
    "\n",
    "        plt.tight_layout()  # Optional, for better spacing between subplots\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce RL, RT plots for all the q2 bin, in W2\n",
    "df[\"Hbc_Sig(GeV)\"]=df[\"bc_q2_w2\"]*df[\"Hcc_Sig(GeV)\"]\n",
    "df[\"Hbc_error(GeV)\"]=df[\"bc_q2_w2\"]*df[\"Hcc_error(GeV)\"]\n",
    "# df[\"Hbc_Sig(GeV)\"]=df[\"Hcc_Sig(GeV)\"]\n",
    "# df[\"Hbc_error(GeV)\"]=df[\"Hcc_error(GeV)\"]\n",
    "\n",
    "Photon_plotting = pd.read_csv(\"Photon_plotting.csv\")\n",
    "Ryan = pd.read_csv(\"Ryan_bin_centered.csv\")\n",
    "def append_row(df, row):\n",
    "    return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
    "\n",
    "# eq. 28: for theta = 180,\n",
    "# RT = ((E0/(E0+Veff))**2) * ((Q2eff/(2*alpha*Eprime_eff))**2 ) * cross\n",
    "# df_Ryan = df.loc[df['dataSet']==17].copy()\n",
    "# df_Ryan['RT28'] = (\n",
    "#         (df_Ryan['E0']/df_Ryan['Eeff'])**2\n",
    "#     )*(\n",
    "#        (df_Ryan['Q2eff']/(\n",
    "#               2*alpha_fine*df_Ryan['Eprime_eff']\n",
    "#        ))**2 \n",
    "#     )*df_Ryan['cross']/(((0.1973269**2)*1e10))\n",
    "\n",
    "# plot Sheren Alsami's data\n",
    "df_Sheren = pd.read_excel('Sheren_plotting.xlsx')\n",
    "Sheren_q2s = [0.5,0.8,1.25,1.75,2.25,2.75,3.25,3.75]\n",
    "\n",
    "def linear_model(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "# Yamaguchi_qvs = [0.148,0.167,0.205,0.24,0.3]\n",
    "# Jourdan_qvs = [0.3,0.38,0.57]\n",
    "# Barr_qvs = [0.3,0.4,0.55,]\n",
    "# Create a PdfPages object to save plots to a PDF file\n",
    "\n",
    "# with PdfPages('curve_fit/curve_fit_'+str(qvcenters[inspect_columns])+'.pdf') as pdf:\n",
    "with PdfPages('figures/RLRT_Q2bin_W2.pdf') as pdf:\n",
    "    for i in range(len(Q2centers)):\n",
    "        Q2center = Q2centers[i]\n",
    "        Q2center_data = Q2center_datas[i]\n",
    "        qvcenter = qvcenters[i]\n",
    "        # qvcenter_data = Qvcenter_datas[i]\n",
    "        # qv2center = qvcenter**2\n",
    "        Q2bin_name = Q2bin_names[i]\n",
    "        # W2width = W2widths[i]\n",
    "        W2width = W2widths[i]\n",
    "        Exwidth = 0.02\n",
    "        bin_data = df.loc[df['Q2center']==Q2center].copy()\n",
    "        # drop dataset 13, 18, 19, 21\n",
    "        fit = pd.DataFrame(columns=['W2','nu','RL','RLerr','RT','RTerr','Chi2',\n",
    "                                        'num_points'])\n",
    "\n",
    "\n",
    "        \n",
    "        RLs = []\n",
    "        RLerrs = []\n",
    "        RTs = []\n",
    "        RTerrs = []\n",
    "        nus = []\n",
    "        RxQ2s = []\n",
    "        RxQ2_errs = []\n",
    "        Exs = []\n",
    "        W2s = []\n",
    "\n",
    "        # nu_grid = np.arange(0.0,2.5,nuwidth*2)\n",
    "        # W2_grid = mass_nucleon**2+2*mass_nucleon*nu_grid-Q2center\n",
    "        W2_grid = np.arange(mass_nucleon**2+2*mass_nucleon*0-Q2center,\n",
    "                            mass_nucleon**2+2*mass_nucleon*2.5-Q2center,\n",
    "                            W2width*2)\n",
    "        \n",
    "\n",
    "        \n",
    "        # for nu in nu_grid:\n",
    "        for W2 in W2_grid:\n",
    "        # for Ex in Ex_grid: \n",
    "            nu = (W2 - mass_nucleon**2 + Q2center)/(2*mass_nucleon)\n",
    "            # W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2center\n",
    "\n",
    "            Ex = nu-Q2center/(2*mass_C12)\n",
    "            if Ex < 0:\n",
    "                continue\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            # q3momt_squared = Q2center+nu**2\n",
    "            qv2 = Q2center+nu**2\n",
    "            # Q2 = qvcenter**2-nu**2\n",
    "            # if Ex >= 0.05:\n",
    "            #     width = 0.01\n",
    "            # else:\n",
    "            #     width = 0.01\n",
    "\n",
    "            # picked = bin_data.loc[((Ex-Exwidth)<=df[\"Ex\"]) & (df[\"Ex\"]<=(Ex+Exwidth)) & (0.030<=df[\"Ex\"])]\n",
    "            # picked = bin_data.loc[((nu-nuwidth)<=df[\"nu\"]) & (df[\"nu\"]<=(nu+nuwidth)) & (0.030<=df[\"Ex\"])]\n",
    "            picked = bin_data.loc[(bin_data['W2']>=W2-W2width) & (bin_data['W2']<=W2+W2width)]\n",
    "            # picked = bin_data.loc[((nu-nuwidth)<=bin_data[\"nu\"]) & (bin_data[\"nu\"]<=(nu+nuwidth))]\n",
    "\n",
    "\n",
    "            # picked = picked.drop_duplicates(keep=\"last\")\n",
    "            x = np.array(picked[\"epsilon\"].values)\n",
    "            y = np.array(picked[\"Hbc_Sig(GeV)\"].values)\n",
    "            y_err = np.array(picked[\"Hbc_error(GeV)\"].values)\n",
    "            \n",
    "            if len(y)>2 and (np.max(x)-np.min(x))>=0.2:\n",
    "                if len(y)==2:\n",
    "                    # print(\"len(y)==2\")\n",
    "                    # duplicated_values = np.concatenate([original_values + 0.1 * original_errors,\n",
    "                    #                     original_values - 0.1 * original_errors])\n",
    "                    # duplicated_errors = original_errors * 1.414\n",
    "                    # duplicated_errors = np.repeat(duplicated_errors, 2)  # Repeat each error twice\n",
    "                    x = np.concatenate([x, x])\n",
    "                    y = np.concatenate([y+0.1*y_err, y-0.1*y_err])\n",
    "                    y_err = y_err * 1.414\n",
    "                    y_err = np.concatenate([y_err, y_err])\n",
    "                params, covariance = curve_fit(linear_model, x, y, sigma=y_err, absolute_sigma=True)\n",
    "\n",
    "                a_opt, b_opt = params\n",
    "                a_err, b_err = np.sqrt(np.diag(covariance))\n",
    "                Chi2 = np.sum(np.square((y-linear_model(x,a_opt,b_opt))/y_err))\n",
    "                RL = a_opt/1000\n",
    "                RT = (2*b_opt*Q2center/qv2)/1000\n",
    "                # if RL>=0 and RT>=0:\n",
    "                RLs.append(RL)\n",
    "                RLerr = a_err/1000 \n",
    "                RLerrs.append(RLerr)\n",
    "                RTs.append(RT)\n",
    "                RTerr = (2*b_err*Q2center/qv2)/1000\n",
    "                RTerrs.append(RTerr)\n",
    "                RxQ2s.append( (2*Q2center/qv2)*RL/RT)\n",
    "                RxQ2_err = np.abs ((2*Q2center/qv2)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
    "                RxQ2_errs.append(RxQ2_err)\n",
    "                W2s.append(W2)\n",
    "                nus.append(nu)\n",
    "\n",
    "                # new_row = {'A': 1, 'B': 2, 'C': 3}   \n",
    "                new_row = pd.Series({'W2':W2,'nu':nu,'RL':RL,'RLerr':RLerr,'RT':RT,'RTerr':RTerr,'Chi2':Chi2,\n",
    "                                    'num_points':len(y)})             \n",
    "                fit = append_row(fit,new_row)\n",
    "\n",
    "        fit['Chi2_DoF']=fit['Chi2']/(fit['num_points']-2)\n",
    "        \n",
    "        fig, axs = plt.subplots(3, 1, figsize=(8, 12))  # 3 row, 1 columns\n",
    "\n",
    "\n",
    "        tick_spacing = 0.05\n",
    "\n",
    "\n",
    "        try:\n",
    "            responseq2_plotting = Q2center_data.loc[(Q2center_data['W2']<=fit['W2'].max())]\n",
    "            # responseq2_plotting = qvcenter_data.loc[qvcenter_data['nu']<=photon_data['nu']]\n",
    "            # responseq2_plotting = picked.loc[picked['nu']<=np.max(nus)]\n",
    "        except ValueError:\n",
    "            print(\"ValueError: no data points\")\n",
    "        axs[0].plot(responseq2_plotting['W2'],responseq2_plotting[\"RL\"],label=\"Fortran RL\", linestyle='dotted',color='black')    \n",
    "        # axs[0].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RL_fortran_qvcenter_nu\"],label=\"Fortran RL\", s=3,color='black')    \n",
    "        axs[0].errorbar(fit['W2'], fit['RL'], yerr = fit['RLerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[0].scatter(fit['W2'], fit['RL'],marker='D',s=6,color='red',label=\"$Q2_{center}:$\"+str(Q2center))\n",
    "        axs[0].set_title(\"Q2:\"+Q2bin_name)\n",
    "        axs[0].set_xlabel(\"$W^2 (GeV)$\")\n",
    "        axs[0].set_ylabel(\"$R_L$\")\n",
    "        axs[0].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[0].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[0].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        axs[1].plot(responseq2_plotting['W2'],responseq2_plotting[\"RT\"],label=\"Fortran RT\",linestyle='dotted',color='black')\n",
    "        # axs[1].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RT_fortran_qvcenter_nu\"],label=\"Fortran RT\", s=3,color='black')\n",
    "        axs[1].errorbar(fit['W2'], fit['RT'], yerr = fit['RTerr'], color='orange', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[1].scatter(fit['W2'], fit['RT'],marker='D',s=6,color='red',label=\"$Q2_{center}:$\"+str(Q2center))\n",
    "        axs[1].set_title(\"Q2:\"+Q2bin_name)\n",
    "        axs[1].set_xlabel(\"$W^2 (GeV)$\")\n",
    "        axs[1].set_ylabel(\"$R_T$\")\n",
    "        axs[1].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[1].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[1].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "\n",
    "        if Q2center in Sheren_q2s:\n",
    "            Sheren = df_Sheren.loc[df_Sheren['Q2']==Q2center]\n",
    "            axs[0].errorbar(Sheren['W2'], Sheren['RL']*12, yerr = Sheren['RLerr']*12, color='lightblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[0].scatter(Sheren['W2'], Sheren['RL']*12,marker='D',s=6,color='blue',label=\"Sheren\")\n",
    "            axs[1].errorbar(Sheren['W2'], Sheren['RT']*12, yerr = Sheren['RTerr']*12, color='lightblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Sheren['W2'], Sheren['RT']*12,marker='D',s=6,color='blue',label=\"Sheren\")\n",
    "            \n",
    "\n",
    "\n",
    "        # Q2 = qv**2-nu**2\n",
    "        # W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2center\n",
    "\n",
    "        W_peaks = np.array([0.93,1.07,1.23]) \n",
    "        W_colors = ['orangered','forestgreen','royalblue']\n",
    "        # 0.8649, 1.1449, 1.5129\n",
    "        for i in range(len(W_peaks)):\n",
    "            # axs[0].axvline(x=0.025+(W_peaks[i]**2-mass_nucleon**2+Q2center)/(2*mass_nucleon), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            # axs[1].axvline(x=0.025+(W_peaks[i]**2-mass_nucleon**2+Q2center)/(2*mass_nucleon), color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            axs[0].axvline(x=W_peaks[i]**2, color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            axs[1].axvline(x=W_peaks[i]**2, color = W_colors[i], linestyle='dotted',label='W = '+str(W_peaks[i]))\n",
    "            \n",
    "        # axs[0].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(Q2center))\n",
    "        # axs[1].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(Q2center))\n",
    "\n",
    "\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "        # fig.savefig('figs/FitEx_Qv_'+str(qvcenter)+'.png')\n",
    "\n",
    "        axs[2].scatter(fit['W2'],fit['Chi2_DoF'],color='orange',s=10,label='$\\chi^2/DoF$')\n",
    "        axs[2].set_title('$\\chi^2/DoF$')\n",
    "        axs[2].set_xlabel(\"W^2 (GeV)$\")\n",
    "        axs[2].set_ylabel(\"$\\chi^2/DoF$\")\n",
    "        axs[2].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[2].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        axs[2].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "\n",
    "        axs[0].set_xlim(fit['W2'].min()*0.98, fit['W2'].max()*1.02)\n",
    "        axs[1].set_xlim(fit['W2'].min()*0.98, fit['W2'].max()*1.02)\n",
    "        axs[2].set_xlim(fit['W2'].min()*0.98, fit['W2'].max()*1.02)\n",
    "        if qvcenter >= 0.38:\n",
    "            axs[0].set_ylim(np.min([np.min(fit['RL'])*1.02,0]),np.max(fit['RL'])*1.02)\n",
    "            axs[1].set_ylim(np.min([np.min(fit['RT'])*1.02,0]),np.max(fit['RT'])*1.02)\n",
    "            axs[2].set_ylim(0.0,np.max(fit['Chi2_DoF'])*1.02)\n",
    "\n",
    "        axs[0].legend()\n",
    "        axs[1].legend()\n",
    "        axs[2].legend()\n",
    "\n",
    "        plt.tight_layout()  # Optional, for better spacing between subplots\n",
    "        plt.show()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (archived) plot SF_FSI\n",
    "for i in range(1,11):\n",
    "    qvcenter = qvcenters[i]\n",
    "    qvcenter_MeV = int(qvcenters[i]*1000)\n",
    "\n",
    "    df_SF = pd.read_csv('SF_FSI/Resp_FSI_12C_'+str(qvcenter_MeV)+'_SF.txt',delim_whitespace=True,header=None)\n",
    "    df_SF.columns = ['nu','RL','RT']\n",
    "    fig,axs = plt.subplots(1,2,figsize=(12,6))\n",
    "    axs[0].scatter(df_SF['nu']/1000,df_SF['RL'],label='RL',s=5)\n",
    "    axs[0].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(qvcenter))\n",
    "\n",
    "    axs[1].scatter(df_SF['nu']/1000,df_SF['RT'],label='RT',s=10)\n",
    "    axs[1].axvline(x=qvcenter, color = 'brown', linestyle='dashdot',label='nu = '+str(qvcenter))\n",
    "\n",
    "    axs[0].set_title('SF FSI Qv = '+str(qvcenter))\n",
    "    axs[0].set_xlabel('nu (GeV)')\n",
    "    axs[0].set_ylabel('RL')\n",
    "    axs[0].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    axs[0].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    axs[0].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "    axs[0].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "    axs[0].legend()\n",
    "    \n",
    "    axs[1].set_title('SF FSI Qv = '+str(qvcenter))\n",
    "    axs[1].set_xlabel('nu (GeV)')\n",
    "    axs[1].set_ylabel('RT')\n",
    "    axs[1].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    axs[1].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    axs[1].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "    axs[1].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "    axs[1].legend()\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 23: new plots Qv, nu\n",
    "# inspect_columns = [0]\n",
    "print(qvcenters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 25: plots settings\n",
    "figsize = ((4*1.25), (3*1.25)*3)\n",
    "inspect_columns = [0]\n",
    "errorbar_setting = {'markersize':'0','capsize':0,'lw':0.5,'fmt':'D','ecolor':'black','elinewidth':0.5,'zorder':-1}\n",
    "our_scatter_setting = {'s':10,'marker':'D','edgecolors':'black','linewidth':0.5,'zorder':2}\n",
    "scatter_setting = {'s':5,'marker':'D','edgecolors':'black','linewidth':0.5,'zorder':1}\n",
    "# hist_settings = {'bins':50, 'density': True, 'histtype':'step'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/3218240926.py:129: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n"
     ]
    }
   ],
   "source": [
    "# Feb 25: new plots in qv bin with journal style\n",
    "# produce RL, RT plots for all the qv bin, in nu\n",
    "# df[\"Hbc_Sig(GeV)\"]=df[\"bc_qv_nu\"]*df[\"Hcc_Sig(GeV)\"]\n",
    "# df[\"Hbc_error(GeV)\"]=df[\"bc_qv_nu\"]*df[\"Hcc_error(GeV)\"]\n",
    "\n",
    "Photon_plotting = pd.read_csv(\"Photon_plotting.csv\")\n",
    "Ryan = pd.read_csv(\"Ryan_bin_centered.csv\")\n",
    "def append_row(df, row):\n",
    "    return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
    "\n",
    "# eq. 28: for theta = 180,\n",
    "# RT = ((E0/(E0+Veff))**2) * ((Q2eff/(2*alpha*Eprime_eff))**2 ) * cross\n",
    "df_Ryan = df.loc[df['dataSet']==17].copy()\n",
    "df_Ryan['RT28'] = (\n",
    "        (df_Ryan['E0']/df_Ryan['Eeff'])**2\n",
    "    )*(\n",
    "       (df_Ryan['Q2eff']/(\n",
    "              2*alpha_fine*df_Ryan['Eprime_eff']\n",
    "       ))**2 \n",
    "    )*df_Ryan['cross']/(((0.1973269**2)*1e10))\n",
    "\n",
    "\n",
    "def linear_model(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "Yamaguchi_qvs = [0.148,0.167,0.205,0.24,0.3]\n",
    "Jourdan_qvs = [0.3,0.38,0.57]\n",
    "Barr_qvs = [0.3,0.4,0.55,]\n",
    "SF_FSI_qvs = [0.148,0.167,0.205,0.24,0.3,0.38,0.475,0.57,0.649,0.756]\n",
    "# Create a PdfPages object to save plots to a PDF file\n",
    "\n",
    "# with PdfPages('curve_fit/curve_fit_'+str(qvcenters[inspect_columns])+'.pdf') as pdf:\n",
    "# for i in inspect_columns:\n",
    "for i in range(len(qvcenters)):\n",
    "    qvcenter = qvcenters[i]\n",
    "    with PdfPages('curve_fit/curve_fit_qv_'+str(qvcenter)+'.pdf') as pdf:\n",
    "        qvcenter_data = Qvcenter_datas[i]\n",
    "        qv2center = qvcenter**2\n",
    "        qvbin_name = qvbin_names[i]\n",
    "        # W2width = W2widths[i]\n",
    "        # Exwidth = 0.02\n",
    "        bin_data = df.loc[df['qvcenter']==qvcenter].copy()\n",
    "        # drop dataset 13, 18, 19, 21\n",
    "        fit = pd.DataFrame(columns=['nu','RL','RLerr','RT','RTerr','Chi2','num_points'])\n",
    "        nuwidth = nuwidths[i]\n",
    "\n",
    "\n",
    "        \n",
    "        RLs = []\n",
    "        RLerrs = []\n",
    "        RTs = []\n",
    "        RTerrs = []\n",
    "        nus = []\n",
    "        RxQ2s = []\n",
    "        RxQ2_errs = []\n",
    "        Exs = []\n",
    "\n",
    "        # formulate 0 < nu < q3\n",
    "\n",
    "        nu_grid = np.arange(0,qvcenter,nuwidth*2)\n",
    "        Q2_grid = qvcenter**2-nu_grid**2\n",
    "        Ex_grid = nu_grid-Q2_grid/(2*mass_C12)\n",
    "        W2_grid = mass_nucleon**2+2*mass_nucleon*nu_grid-Q2_grid\n",
    "\n",
    "        \n",
    "        # for nu in nu_grid:\n",
    "        for j in range(len(nu_grid)-1):\n",
    "            nu = nu_grid[j]\n",
    "            Q2 = Q2_grid[j]\n",
    "            Ex = Ex_grid[j]\n",
    "            W2 = W2_grid[j]\n",
    "\n",
    "            # Ex = nu-(qvcenter**2-nu**2)/(2*mass_C12)\n",
    "            if Ex < 0:\n",
    "                continue\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            # qv2 = Q2center+nu**2\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            # Q2 = qvcenter**2-nu**2\n",
    "            # W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2\n",
    "\n",
    "            # picked = bin_data.loc[((nu-nuwidth)<=bin_data[\"nu\"]) & (bin_data[\"nu\"]<=(nu+nuwidth))]\n",
    "\n",
    "            # picked = bin_data.loc[(bin_data[\"nu\"]>=nu_grid[j]) & (bin_data[\"nu\"]<=nu_grid[j+1])]\n",
    "            if nu <= 0.05:\n",
    "                picked = bin_data.loc[(bin_data['Ex']>=Ex_grid[j]) & (bin_data['Ex']<Ex_grid[j+1])].copy()\n",
    "                picked['Hbc_Sig(GeV)'] = picked['bc_qv_ex']*picked['Hcc_Sig(GeV)']\n",
    "                picked['Hbc_error(GeV)'] = picked['bc_qv_ex']*picked['Hcc_error(GeV)']\n",
    "            else:\n",
    "                picked = bin_data.loc[(bin_data['W2']>=W2_grid[j]) & (bin_data['W2']<W2_grid[j+1])].copy()\n",
    "                picked['Hbc_Sig(GeV)'] = picked['bc_qv_w2']*picked['Hcc_Sig(GeV)']\n",
    "                picked['Hbc_error(GeV)'] = picked['bc_qv_w2']*picked['Hcc_error(GeV)']            \n",
    "            x = np.array(picked[\"epsilon\"].values)\n",
    "            y = np.array(picked[\"Hbc_Sig(GeV)\"].values)\n",
    "            y_err = np.array(picked[\"Hbc_error(GeV)\"].values)\n",
    "            # picked = picked.drop_duplicates(keep=\"last\")\n",
    "            # x = np.array(picked[\"epsilon\"].values)\n",
    "            # y = np.array((picked[\"bc_qv_nu\"]*picked[\"Hcc_Sig(GeV)\"]).values)\n",
    "            # y_err = np.array((picked[\"bc_qv_nu\"]*picked[\"Hbc_error(GeV)\"]).values)\n",
    "            \n",
    "            if len(y)>2 and (np.max(x)-np.min(x))>=0.25:\n",
    "                if len(y)==2:\n",
    "                    x = np.concatenate([x, x])\n",
    "                    y = np.concatenate([y+0.1*y_err, y-0.1*y_err])\n",
    "                    y_err = y_err * 1.414\n",
    "                    y_err = np.concatenate([y_err, y_err])\n",
    "\n",
    "                params, covariance = curve_fit(linear_model, x, y, sigma=y_err, absolute_sigma=True)\n",
    "                a_opt, b_opt = params\n",
    "                a_err, b_err = np.sqrt(np.diag(covariance))\n",
    "                Chi2 = np.sum(np.square((y-linear_model(x,a_opt,b_opt))/y_err))\n",
    "                RL = a_opt/1000\n",
    "                RLerr = a_err/1000 \n",
    "                RT = (2*b_opt*Q2/qv2center)/1000\n",
    "                RTerr = (2*b_err*Q2/qv2center)/1000\n",
    "                if RL < 0:\n",
    "                    RL = 0\n",
    "                    weights = 1/(y_err**2)\n",
    "                    average = np.sum(y*weights)/np.sum(weights)\n",
    "                    RT = (2*average*Q2/qv2center)/1000\n",
    "                    # RTerr = (2*np.sqrt(1/np.sum(weights))*Q2/qv2center)/1000\n",
    "\n",
    "                # if RL>=0 and RT>=0:\n",
    "                RLs.append(RL)\n",
    "                RLerrs.append(RLerr)\n",
    "                RTs.append(RT)\n",
    "                RTerrs.append(RTerr)\n",
    "                RxQ2s.append( (2*Q2/qv2center)*RL/RT)\n",
    "                RxQ2_err = np.abs ((2*Q2/qv2center)) * (RL/RT)* np.sqrt( (RLerr/RL)**2 + (RTerr/RT)**2 )\n",
    "                RxQ2_errs.append(RxQ2_err)\n",
    "                # W2s.append(W2)\n",
    "                nus.append(nu+nuwidth)\n",
    "                new_row = pd.Series({'nu':nu,'RL':RL,'RLerr':RLerr,'RT':RT,'RTerr':RTerr,'Chi2':Chi2,\n",
    "                                    'num_points':len(y)})             \n",
    "                fit = append_row(fit,new_row)\n",
    "                #____________________________________________________________________________________________________________________\n",
    "                \n",
    "                # fig = plt.figure(figsize=(12,6))\n",
    "                # plt.plot(x,linear_model(x,a_opt,b_opt),color='gray',label = 'y='+str(round(a_opt,3))\n",
    "                #         +'*x+'+str(round(b_opt,3))+'\\nRL,RT:'+str(round(RL,3))+','+str(round(RT,3)))\n",
    "                # datasets = picked['dataSet'].unique()\n",
    "                            \n",
    "                # plt.title('$Q^{3}_{center}$:'+str(qvcenter)+'   Ex:'+str(round(Ex,3))+'   nu:'+str(round(nu,3))+'    RL,RT error: '+round_sig_3(RLerr)+','+round_sig_3(RTerr)\n",
    "                #           +'   $\\chi^2$:'+str(round(Chi2,1))+'   DoF:'+str(len(y)-2) +'   $\\\\frac{\\chi^2}{DoF}$:'+str(round(Chi2/(len(y)-2),1)))\n",
    "\n",
    "                # for dataset in datasets:\n",
    "                #     picked_dataset = picked.loc[picked['dataSet']==dataset]\n",
    "                #     plt.errorbar(picked_dataset['epsilon'],picked_dataset['Hbc_Sig(GeV)'],yerr=picked_dataset['Hbc_error(GeV)'],\n",
    "                #                  fmt ='.',capsize=3,markersize='3')\n",
    "                #     plt.scatter(picked_dataset['epsilon'],picked_dataset['Hbc_Sig(GeV)'],s=10, label = str(dataset)+' '+dataSet_to_name[dataset])\n",
    "\n",
    "                # # plt.scatter(x,y,s=1)\n",
    "                # plt.xlabel('epsilon')\n",
    "                # plt.ylabel('Hbc')\n",
    "                # plt.legend()\n",
    "                # pdf.savefig(fig)\n",
    "                #____________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "        # fit = pd.DataFrame({'nu':nus,'RL':RLs,'RLerr':RLerrs,'RT':RTs,'RTerr':RTerrs})\n",
    "        fit['Chi2_DoF']=fit['Chi2']/(fit['num_points']-2)\n",
    "        fig, axs = plt.subplots(3, 1, figsize=figsize)  # 3 row, 1 columns\n",
    "\n",
    "\n",
    "        tick_spacing = 0.05\n",
    "\n",
    "\n",
    "        try:\n",
    "            responseq2_plotting = qvcenter_data.loc[(qvcenter_data['nu']<=qvcenter)]\n",
    "            # responseq2_plotting = qvcenter_data.loc[qvcenter_data['nu']<=photon_data['nu']]\n",
    "            # responseq2_plotting = picked.loc[picked['nu']<=np.max(nus)]\n",
    "        except ValueError:\n",
    "            print(\"ValueError: no data points\")\n",
    "        axs[0].plot(responseq2_plotting['nu'],responseq2_plotting[\"RL\"],color='black',label=\"RL Total Christy-Bodek Fit\", linestyle='solid')    \n",
    "        axs[0].plot(responseq2_plotting['nu'],responseq2_plotting[\"RLQE\"],color='black',label=\"RL QE Christy-Bodek Fit\", linestyle='dotted')    \n",
    "        # axs[0].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RL_fortran_qvcenter_nu\"],label=\"Fortran RL\", s=3,color='black')    \n",
    "        \n",
    "        # axs[0].errorbar(fit['nu'], fit['RL'], yerr = fit['RLerr'], color='red', fmt ='.',capsize=3,markersize='3')\n",
    "        # axs[0].scatter(fit['nu'], fit['RL'],marker='D',s=6,color='red',label='RL this analysis')\n",
    "        # new plt style setting\n",
    "        axs[0].errorbar(fit['nu'], fit['RL'], yerr = fit['RLerr'], color='red', **errorbar_setting)\n",
    "        axs[0].scatter(fit['nu'], fit['RL'],color='red',label='RL this analysis',**our_scatter_setting)\n",
    "        axs[0].set_title(\"$\\mathbf{q}=$\"+str(qvcenter)+' bin:'+qvbin_name)\n",
    "        axs[0].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[0].set_ylabel(\"$R_L$\")\n",
    "        # axs[0].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[0].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[0].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        # axs[0].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        axs[1].plot(responseq2_plotting['nu'],responseq2_plotting[\"RT\"],color='black',label=\"RT Total Christy-Bodek Fit\",linestyle='solid')\n",
    "        axs[1].plot(responseq2_plotting['nu'],responseq2_plotting[\"RTQE\"],color='black',label=\"RT QE+TE Christy-Bodek Fit\",linestyle='dotted')\n",
    "        # axs[1].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RT_fortran_qvcenter_nu\"],label=\"Fortran RT\", s=3,color='black')\n",
    "        \n",
    "\n",
    "        # axs[1].errorbar(fit['nu'], fit['RT'], yerr = fit['RTerr'], color='red', fmt ='.',capsize=3,markersize='3')\n",
    "        # axs[1].scatter(fit['nu'], fit['RT'],marker='D',s=6,color='red',label='RT this analysis')\n",
    "        # new plt style setting\n",
    "        axs[1].errorbar(fit['nu'], fit['RT'], yerr = fit['RTerr'], color='red', **errorbar_setting)\n",
    "        axs[1].scatter(fit['nu'], fit['RT'],color='red',label='RT this analysis',**our_scatter_setting)\n",
    "        axs[1].set_title(\"$\\mathbf{q}=$\"+str(qvcenter)+' bin:'+qvbin_name)\n",
    "        axs[1].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[1].set_ylabel(\"$R_T$\")\n",
    "        # axs[1].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[1].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[1].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        # axs[1].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        # photon-production data\n",
    "        # if qvcenter == 0.1:\n",
    "        #     photon_data = Photon_plotting.loc[Photon_plotting['nu']<=qvcenter]\n",
    "        #     axs[1].scatter(photon_data['nu'],photon_data[\"RT\"],marker='^',s=20,color='fuchsia',label=\"RT Photo-production ($Q^2=0$)\")\n",
    "        #     axs[1].plot(photon_data['nu'],photon_data[\"RT\"],color='gray',lw=1)\n",
    "        # else:\n",
    "        photon_index = (Photon_plotting['qv'] - qvcenter).abs().idxmin()\n",
    "        photon_data = Photon_plotting.loc[photon_index]\n",
    "        axs[1].scatter(photon_data['nu'],photon_data[\"RT\"],marker='^',s=40,color='lime',label=\"RT Photo-production\")\n",
    "\n",
    "        # if qvcenter in Ryan['qvcenter'].unique():\n",
    "            # Ryan_data = Ryan.loc[Ryan['qvcenter']==qvcenter]\n",
    "            # axs[1].errorbar(Ryan_data['nu'],Ryan_data[\"RT_bc\"], yerr = Ryan_data[\"RTerr_bc\"], color='plum', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[1].scatter(Ryan_data['nu'],Ryan_data[\"RT_bc\"],marker='D',s=6,color='plum',label=\"Ryan bin_centered\")\n",
    "\n",
    "            # Ryan_data = df_Ry\n",
    "            # an.loc[df_Ryan['qvcenter']==qvcenter]\n",
    "            # axs[1].scatter(Ryan_data['nu'],Ryan_data[\"RT28\"],marker='D',s=6,color='plum',label=\"RT Ryan\")\n",
    "\n",
    "        \n",
    "        if qvcenter in Jourdan_qvs:\n",
    "            Jourdan_data = pd.read_excel('Jourdan_RL_RT_plots.xlsx')\n",
    "            Jourdan_data = Jourdan_data.loc[Jourdan_data['Q']==qvcenter]\n",
    "            # axs[0].errorbar(Jourdan_data['nu'],Jourdan_data[\"RL\"], yerr = Jourdan_data[\"Error(RL)\"], color='darkorange', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[0].scatter(Jourdan_data['nu'],Jourdan_data[\"RL\"],marker='D',s=6,color='darkorange',label=\"RL Jourdan\")\n",
    "            # axs[1].errorbar(Jourdan_data['nu'],Jourdan_data[\"RT\"], yerr = Jourdan_data[\"Error(RT)\"], color='darkorange', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[1].scatter(Jourdan_data['nu'],Jourdan_data[\"RT\"],marker='D',s=6,color='darkorange',label=\"RT Jourdan\")\n",
    "            axs[0].errorbar(Jourdan_data['nu'],Jourdan_data[\"RL\"], yerr = Jourdan_data[\"Error(RL)\"], color='darkorange', **errorbar_setting)\n",
    "            axs[0].scatter(Jourdan_data['nu'],Jourdan_data[\"RL\"],color='darkorange',label=\"RL Jourdan\", **scatter_setting)\n",
    "            axs[1].errorbar(Jourdan_data['nu'],Jourdan_data[\"RT\"], yerr = Jourdan_data[\"Error(RT)\"], color='darkorange', **errorbar_setting)\n",
    "            axs[1].scatter(Jourdan_data['nu'],Jourdan_data[\"RT\"],color='darkorange',label=\"RT Jourdan\", **scatter_setting)\n",
    "\n",
    "\n",
    "\n",
    "            # plot barreau along with Ryan\n",
    "            Bar_RL = pd.read_csv('Barreau/Barreau_RL_qvcenter_'+str(qvcenter)+'.csv')\n",
    "            Bar_RT = pd.read_csv('Barreau/Barreau_RT_qvcenter_'+str(qvcenter)+'.csv')\n",
    "            # axs[0].errorbar(Bar_RL['nu'],Bar_RL[\"RLbc\"], yerr = Bar_RL[\"RLerr_bc\"], color='blue', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[0].scatter(Bar_RL['nu'],Bar_RL[\"RLbc\"],marker='D',s=6,color='blue',label=\"RL Barreau bin-centered\")\n",
    "            # axs[1].errorbar(Bar_RT['nu'],Bar_RT[\"RTbc\"], yerr = Bar_RT[\"RTerr_bc\"], color='blue', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[1].scatter(Bar_RT['nu'],Bar_RT[\"RTbc\"],marker='D',s=6,color='blue',label=\"RT Barreau bin-centered\")\n",
    "            axs[0].errorbar(Bar_RL['nu'],Bar_RL[\"RLbc\"], yerr = Bar_RL[\"RLerr_bc\"], color='blue', **errorbar_setting)\n",
    "            axs[0].scatter(Bar_RL['nu'],Bar_RL[\"RLbc\"],color='blue',label=\"RL Barreau bin-centered\", **scatter_setting)\n",
    "            axs[1].errorbar(Bar_RT['nu'],Bar_RT[\"RTbc\"], yerr = Bar_RT[\"RTerr_bc\"], color='blue', **errorbar_setting)\n",
    "            axs[1].scatter(Bar_RT['nu'],Bar_RT[\"RTbc\"],color='blue',label=\"RT Barreau bin-centered\", **scatter_setting)\n",
    "\n",
    "            # if qvcenter == 0.3:\n",
    "            #     bar_qv = 0.3    \n",
    "            # if qvcenter == 0.38:\n",
    "            #     bar_qv = 0.4\n",
    "            # elif qvcenter == 0.57:\n",
    "            #     bar_qv = 0.55 \n",
    "            # Bar_RL = pd.read_excel('Barreau_plotting.xlsx',sheet_name='RL_qv_'+str(bar_qv))\n",
    "            # Bar_RL.columns = ['qv','nu','RL','RLerr']\n",
    "            # axs[0].errorbar(Bar_RL['nu'],Bar_RL[\"RL\"], yerr = Bar_RL[\"RLerr\"], color='steelblue', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[0].scatter(Bar_RL['nu'],Bar_RL[\"RL\"],marker='D',s=6,color='blue',label=\"RL Barreau $\\mathbf{q}=$\"+str(bar_qv))\n",
    "\n",
    "            # Bar_RT = pd.read_excel('Barreau_plotting.xlsx',sheet_name='RT_qv_'+str(bar_qv))\n",
    "            # Bar_RT.columns = ['qv','nu','RT','RTerr']\n",
    "            # axs[1].errorbar(Bar_RT['nu'],Bar_RT[\"RT\"], yerr = Bar_RT[\"RTerr\"], color='steelblue', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[1].scatter(Bar_RT['nu'],Bar_RT[\"RT\"],marker='D',s=6,color='blue',label=\"RT Barreau $\\mathbf{q}=$\"+str(bar_qv))\n",
    "\n",
    "        Yam_RLmax = 0\n",
    "        Yam_RTmax = 0\n",
    "        if qvcenter in Yamaguchi_qvs:\n",
    "            Yam_data = pd.read_excel('Yamaguchi_plotting.xlsx',sheet_name='qv_'+str(qvcenter))\n",
    "            # Yam_data['nu_RL'] = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Yam_data['EX_RL'])\n",
    "            # Yam_data['nu_RT'] = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Yam_data['EX_RT'])\n",
    "            # Ex = nu-(qv^2-nu^2)/(2M)\n",
    "            # nu = - M + sqrt(M^2 + qv^2 + 2M*Ex)\n",
    "            # solve quadratic equation\n",
    "            \n",
    "\n",
    "            # axs[0].scatter(Yam_data['nu_RL'],Yam_data[\"RL\"],marker='D',s=6,color='cyan',label=\"RL Yamaguchi\")\n",
    "            # axs[0].plot(Yam_data['nu_RL'],Yam_data[\"RL\"],lw=1,color='black')\n",
    "            # axs[1].scatter(Yam_data['nu_RT'],Yam_data[\"RT\"],marker='D',s=6,color='cyan',label=\"RT Yamaguchi\")\n",
    "            # axs[1].plot(Yam_data['nu_RT'],Yam_data[\"RT\"],lw=1,color='black')\n",
    "            axs[0].scatter(Yam_data['nu_RL'],Yam_data[\"RL\"],color='cyan',label=\"RL Yamaguchi\",**scatter_setting)\n",
    "            axs[0].plot(Yam_data['nu_RL'],Yam_data[\"RL\"],lw=0.5,color='gray',zorder=-2)\n",
    "            axs[1].scatter(Yam_data['nu_RT'],Yam_data[\"RT\"],color='cyan',label=\"RT Yamaguchi\",**scatter_setting)\n",
    "            axs[1].plot(Yam_data['nu_RT'],Yam_data[\"RT\"],lw=0.5,color='gray',zorder=-2)\n",
    "            Yam_RLmax = Yam_data[\"RL\"].max()\n",
    "            Yam_RTmax = Yam_data[\"RT\"].max()\n",
    "            \n",
    "        # goldemberg\n",
    "        if qvcenter == 0.1: \n",
    "            Goldem_data = pd.read_csv('Goldemberger_180.csv')\n",
    "            # axs[1].errorbar(Goldem_data['nu'],Goldem_data[\"RT\"], yerr = Goldem_data[\"error\"], color='skyblue', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[1].scatter(Goldem_data['nu'],Goldem_data[\"RT\"],marker='D',s=6,color='blue',label=\"RT Goldemberg\")\n",
    "            axs[1].errorbar(Goldem_data['nu'],Goldem_data[\"RT\"], yerr = Goldem_data[\"error\"], color='skyblue', **errorbar_setting)\n",
    "            axs[1].scatter(Goldem_data['nu'],Goldem_data[\"RT\"],color='blue',label=\"RT Goldemberg\",**scatter_setting)\n",
    "        # NuWRo\n",
    "        if qvcenter in SF_FSI_qvs:\n",
    "            qvcenter_MeV = int(qvcenter*1000)\n",
    "            df_SF = pd.read_csv('SF_FSI/Resp_FSI_12C_'+str(qvcenter_MeV)+'_SF.txt',delim_whitespace=True,header=None)\n",
    "            df_SF.columns = ['nu','RL','RT']\n",
    "            axs[0].scatter(df_SF['nu']/1000,df_SF['RL'],label='RL QE NuWRo-SF-FSI',color='green',s=5)\n",
    "            axs[1].scatter(df_SF['nu']/1000,df_SF['RT'],label='RT QE NuWRo-SF-FSI',color='green',s=5)\n",
    "\n",
    "            \n",
    "\n",
    "        # W2_peaks = np.array([0.93,1.07,1.23])\n",
    "        W_peaks = np.array([0.93,1.07,1.23]) \n",
    "        W_colors = ['violet','forestgreen','royalblue']\n",
    "        W_height0 = fit['RL'].max()*1.3\n",
    "        W_height1 = fit['RT'].max()*1.3\n",
    "\n",
    "        # 0.8649, 1.1449, 1.5129\n",
    "        for i in range(len(W_peaks)):\n",
    "            location = 0.025-mass_nucleon+np.sqrt(qvcenter**2+W_peaks[i]**2)\n",
    "            if location < qvcenter:\n",
    "                axs[0].axvline(x=location, color = W_colors[i], linestyle='dashed')\n",
    "                axs[0].text(location, W_height0-i*0.08*W_height0 , '$W=$'+str(W_peaks[i]),color = 'black', ha = 'center')\n",
    "            \n",
    "                axs[1].axvline(x=location, color = W_colors[i], linestyle='dashed')\n",
    "                axs[1].text(location, W_height1-i*0.08*W_height1, '$W=$'+str(W_peaks[i]),color = 'black', ha = 'center')\n",
    "        \n",
    "        axs[0].axvline(x=qvcenter, color = 'brown', linestyle='dashdot')\n",
    "        axs[0].text(qvcenter, W_height0*0.9,  f'$\\\\nu={qvcenter}$'+'\\n$(Q^2=0)$' ,color = 'black',ha = 'center')\n",
    "\n",
    "        axs[1].axvline(x=qvcenter, color = 'brown', linestyle='dashdot')\n",
    "        axs[1].text(qvcenter, W_height1*0.9, f'$\\\\nu={qvcenter}$'+'\\n$(Q^2=0)$', color = 'black',ha = 'center')\n",
    "\n",
    "        axs[2].scatter(fit['nu'],fit['Chi2_DoF'],color='orange',s=10,label='$\\chi^2/DoF$')\n",
    "        axs[2].set_title('$\\chi^2/DoF$')\n",
    "        axs[2].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[2].set_ylabel(\"$\\chi^2/DoF$\")\n",
    "        # axs[2].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[2].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[2].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        # axs[2].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "        totalChi2 = np.sum(fit['Chi2'])\n",
    "\n",
    "\n",
    "        axs[0].set_xlim(0.0, qvcenter*1.05)\n",
    "        axs[1].set_xlim(0.0, qvcenter*1.05)\n",
    "        axs[2].set_xlim(0.0, qvcenter*1.05)\n",
    "\n",
    "        axs0_y_low = 0\n",
    "        axs1_y_low = 0\n",
    "        if fit['RL'].min()<0:\n",
    "            axs0_y_low = fit['RL'].min()*1.1\n",
    "        if fit['RT'].min()<0:\n",
    "            axs1_y_low = fit['RT'].min()*1.1\n",
    "        if len(fit['nu']) > 0:\n",
    "            axs[0].set_ylim(axs0_y_low, W_height0*1.5)\n",
    "            axs[1].set_ylim(axs1_y_low, W_height1*1.5)\n",
    "\n",
    "\n",
    "\n",
    "        axs[0].legend()\n",
    "        axs[1].legend()\n",
    "        axs[2].legend()\n",
    "\n",
    "        plt.tight_layout()  # Optional, for better spacing between subplots\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_87640/2952246967.py:2: DeprecationWarning: PdfMerger is deprecated and will be removed in pypdf 5.0.0. Use PdfWriter instead.\n",
      "  merger = PdfMerger()\n"
     ]
    }
   ],
   "source": [
    "# Feb 25 merge PDFs, qv with journal style\n",
    "merger = PdfMerger()\n",
    "for qvcenter in qvcenters:\n",
    "    merger.append('curve_fit/curve_fit_qv_'+str(qvcenter)+'.pdf')\n",
    "merger.write(\"RLRT_qvbins.pdf\")\n",
    "merger.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "1. larger spamer error bar\n",
    "2. nu = qvcenter (Q2 = 0) move up\n",
    "3. don't show our data below 0.25 if Yamaguchi is there\n",
    "4. double nu bin widths at large qv\n",
    "    qv=0.3: last two points need to be combined\n",
    "    qv=0.38: last 6 points need to be combined\n",
    "    qv=0.475: last 4 points need to be combined\n",
    "    qv=0.57: last 11 points need to be combined\n",
    "    qv=0.756: last 12 points need to be combined 4 times wider?\n",
    "5. split 1.302 bin to up and above\n",
    "6. photo production interpolation\n",
    "7. pack 8 RL plots together, 8 RT plots together. Legends on top, seperately\n",
    "8: in talk, show stop at 0.991 (12 plots)\n",
    "9. larger: split into lower nu, higher nu\n",
    "    new bin: qvcenter = 3.500, (2.923~4.500)\n",
    "10. plots of ours and fit, nuwro; plots with otehr's data to comopare\n",
    "11. our compare to theory points\n",
    "12. 0.148, 0.3, 0.475, 0.649 plot with 3 nuwro plots\n",
    "13. 15 min talk and backup\n",
    "    in the talk, first 9 bins\n",
    "        second 9 bins for backup\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:292: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()  # Optional, for better spacing between subplots\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:292: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()  # Optional, for better spacing between subplots\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:292: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()  # Optional, for better spacing between subplots\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:292: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()  # Optional, for better spacing between subplots\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:292: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()  # Optional, for better spacing between subplots\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/3519374142.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Feb 25: new plots in Q2 bin for journal style\n",
    "\n",
    "Photon_plotting = pd.read_csv(\"Photon_plotting.csv\")\n",
    "Ryan = pd.read_csv(\"Ryan_bin_centered.csv\")\n",
    "def append_row(df, row):\n",
    "    return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
    "df_Sheren = pd.read_excel('Sheren_plotting.xlsx')\n",
    "Sheren_q2s = [0.5,0.8,1.25,1.75,2.25,2.75,3.25,3.75]\n",
    "# eq. 28: for theta = 180,\n",
    "# RT = ((E0/(E0+Veff))**2) * ((Q2eff/(2*alpha*Eprime_eff))**2 ) * cross\n",
    "df_Ryan = df.loc[df['dataSet']==17].copy()\n",
    "df_Ryan['RT28'] = (\n",
    "        (df_Ryan['E0']/df_Ryan['Eeff'])**2\n",
    "    )*(\n",
    "       (df_Ryan['Q2eff']/(\n",
    "              2*alpha_fine*df_Ryan['Eprime_eff']\n",
    "       ))**2 \n",
    "    )*df_Ryan['cross']/(((0.1973269**2)*1e10))\n",
    "\n",
    "\n",
    "def linear_model(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "Yamaguchi_qvs = [0.148,0.167,0.205,0.24,0.3]\n",
    "Jourdan_qvs = [0.3,0.38,0.57]\n",
    "Barr_qvs = [0.3,0.4,0.55,]\n",
    "SF_FSI_qvs = [0.148,0.167,0.205,0.24,0.3,0.38,0.475,0.57,0.649,0.756]\n",
    "# Create a PdfPages object to save plots to a PDF file\n",
    "# for i in range(len(Q2centers)):\n",
    "for i in range(len(Q2centers)):\n",
    "    Q2center = Q2centers[i]\n",
    "    with PdfPages('curve_fit/curve_fit_q2_'+str(Q2center)+'.pdf') as pdf:\n",
    "        Q2center_data = Q2center_datas[i]\n",
    "        qvcenter = qvcenters[i]\n",
    "        Q2bin_name = Q2bin_names[i]\n",
    "        bin_data = df.loc[df['Q2center']==Q2center].copy()\n",
    "        fit = pd.DataFrame(columns=['nu','RL','RLerr','RT','RTerr','Chi2','num_points'])\n",
    "        nuwidth = nuwidths[i]\n",
    "\n",
    "        RLs = []\n",
    "        RLerrs = []\n",
    "        RTs = []\n",
    "        RTerrs = []\n",
    "        nus = []\n",
    "        RxQ2s = []\n",
    "        RxQ2_errs = []\n",
    "        Exs = []\n",
    "\n",
    "        nu_grid = np.arange(0,3.5,nuwidth*2)\n",
    "        qv_grid = np.sqrt(Q2center+nu_grid**2)\n",
    "        Ex_grid = nu_grid-Q2center/(2*mass_C12)\n",
    "        W2_grid = mass_nucleon**2+2*mass_nucleon*nu_grid-Q2center\n",
    "\n",
    "        # for nu in nu_grid:\n",
    "        for j in range(len(nu_grid)-1):\n",
    "            nu = nu_grid[j]\n",
    "            qv = qv_grid[j]\n",
    "            Ex = Ex_grid[j]\n",
    "            W2 = W2_grid[j]\n",
    "            if Ex < 0:\n",
    "                continue\n",
    "\n",
    "            # Ex = nu-(qvcenter**2-nu**2)/(2*mass_C12)\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            # qv2 = Q2center+nu**2\n",
    "            # nu = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Ex)\n",
    "            # Q2 = qvcenter**2-nu**2\n",
    "            # W2 = mass_nucleon**2+2*mass_nucleon*nu-Q2\n",
    "\n",
    "            # picked = bin_data.loc[((nu-nuwidth)<=bin_data[\"nu\"]) & (bin_data[\"nu\"]<=(nu+nuwidth))]\n",
    "\n",
    "            # picked = bin_data.loc[(bin_data[\"nu\"]>=nu_grid[j]) & (bin_data[\"nu\"]<=nu_grid[j+1])]\n",
    "            if nu <= 0.05:\n",
    "                picked = bin_data.loc[(bin_data['Ex']>=Ex_grid[j]) & (bin_data['Ex']<Ex_grid[j+1])].copy()\n",
    "                picked['Hbc_Sig(GeV)'] = picked['bc_q2_ex']*picked['Hcc_Sig(GeV)']\n",
    "                picked['Hbc_error(GeV)'] = picked['bc_q2_ex']*picked['Hcc_error(GeV)']\n",
    "            else:\n",
    "                picked = bin_data.loc[(bin_data['W2']>=W2_grid[j]) & (bin_data['W2']<W2_grid[j+1])].copy()\n",
    "                picked['Hbc_Sig(GeV)'] = picked['bc_q2_w2']*picked['Hcc_Sig(GeV)']\n",
    "                picked['Hbc_error(GeV)'] = picked['bc_q2_w2']*picked['Hcc_error(GeV)']            \n",
    "            x = np.array(picked[\"epsilon\"].values)\n",
    "            y = np.array(picked[\"Hbc_Sig(GeV)\"].values)\n",
    "            y_err = np.array(picked[\"Hbc_error(GeV)\"].values)\n",
    "            # picked = picked.drop_duplicates(keep=\"last\")\n",
    "            # x = np.array(picked[\"epsilon\"].values)\n",
    "            # y = np.array((picked[\"bc_qv_nu\"]*picked[\"Hcc_Sig(GeV)\"]).values)\n",
    "            # y_err = np.array((picked[\"bc_qv_nu\"]*picked[\"Hbc_error(GeV)\"]).values)\n",
    "            \n",
    "            if len(y)>2 and (np.max(x)-np.min(x))>=0.25:\n",
    "                if len(y)==2:\n",
    "                    x = np.concatenate([x, x])\n",
    "                    y = np.concatenate([y+0.1*y_err, y-0.1*y_err])\n",
    "                    y_err = y_err * 1.414\n",
    "                    y_err = np.concatenate([y_err, y_err])\n",
    "\n",
    "                params, covariance = curve_fit(linear_model, x, y, sigma=y_err, absolute_sigma=True)\n",
    "                a_opt, b_opt = params\n",
    "                a_err, b_err = np.sqrt(np.diag(covariance))\n",
    "                Chi2 = np.sum(np.square((y-linear_model(x,a_opt,b_opt))/y_err))\n",
    "                RL = a_opt/1000\n",
    "                RLerr = a_err/1000 \n",
    "                RT = (2*b_opt*Q2center/(qv**2))/1000\n",
    "                RTerr = (2*b_err*Q2center/(qv**2))/1000\n",
    "                if RL < 0:\n",
    "                    RL = 0\n",
    "                    weights = 1/(y_err**2)\n",
    "                    average = np.sum(y*weights)/np.sum(weights)\n",
    "                    RT = (2*average*Q2center/(qv**2))/1000\n",
    "                    # RTerr = (2*np.sqrt(1/np.sum(weights))*Q2center/(qv**2))/1000\n",
    "\n",
    "                # if RL>=0 and RT>=0:\n",
    "                RLs.append(RL)\n",
    "                RLerrs.append(RLerr)\n",
    "                RTs.append(RT)\n",
    "                RTerrs.append(RTerr)\n",
    "\n",
    "                nus.append(nu+nuwidth)\n",
    "                new_row = pd.Series({'nu':nu,'RL':RL,'RLerr':RLerr,'RT':RT,'RTerr':RTerr,'Chi2':Chi2,\n",
    "                                    'num_points':len(y)})             \n",
    "                fit = append_row(fit,new_row)\n",
    "                #____________________________________________________________________________________________________________________\n",
    "                \n",
    "                # fig = plt.figure(figsize=(12,6))\n",
    "                # plt.plot(x,linear_model(x,a_opt,b_opt),color='gray',label = 'y='+str(round(a_opt,3))\n",
    "                #         +'*x+'+str(round(b_opt,3))+'\\nRL,RT:'+str(round(RL,3))+','+str(round(RT,3)))\n",
    "                # datasets = picked['dataSet'].unique()\n",
    "                            \n",
    "                # plt.title('$Q^{2}_{center}$:'+str(Q2center)+'   Ex:'+str(round(Ex,3))+'   nu:'+str(round(nu,3))+'    RL,RT error: '+round_sig_3(RLerr)+','+round_sig_3(RTerr)\n",
    "                #           +'   $\\chi^2$:'+str(round(Chi2,1))+'   DoF:'+str(len(y)-2) +'   $\\\\frac{\\chi^2}{DoF}$:'+str(round(Chi2/(len(y)-2),1)))\n",
    "\n",
    "                # for dataset in datasets:\n",
    "                #     picked_dataset = picked.loc[picked['dataSet']==dataset]\n",
    "                #     plt.errorbar(picked_dataset['epsilon'],picked_dataset['Hbc_Sig(GeV)'],yerr=picked_dataset['Hbc_error(GeV)'],\n",
    "                #                  fmt ='.',capsize=3,markersize='3')\n",
    "                #     plt.scatter(picked_dataset['epsilon'],picked_dataset['Hbc_Sig(GeV)'],s=10, label = str(dataset)+' '+dataSet_to_name[dataset])\n",
    "\n",
    "                # # plt.scatter(x,y,s=1)\n",
    "                # plt.xlabel('epsilon')\n",
    "                # plt.ylabel('Hbc')\n",
    "                # plt.legend()\n",
    "                # pdf.savefig(fig)\n",
    "                #____________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "        # fit = pd.DataFrame({'nu':nus,'RL':RLs,'RLerr':RLerrs,'RT':RTs,'RTerr':RTerrs})\n",
    "        fit['Chi2_DoF']=fit['Chi2']/(fit['num_points']-2)\n",
    "        fig, axs = plt.subplots(3, 1, figsize=figsize)  # 3 row, 1 columns\n",
    "\n",
    "        tick_spacing = 0.05\n",
    "\n",
    "        try:\n",
    "            responseq2_plotting = Q2center_data.loc[(Q2center_data['nu']<=fit['nu'].max()*1.1)]\n",
    "            # responseq2_plotting = qvcenter_data.loc[qvcenter_data['nu']<=photon_data['nu']]\n",
    "            # responseq2_plotting = picked.loc[picked['nu']<=np.max(nus)]\n",
    "        except ValueError:\n",
    "            print(\"ValueError: no data points\")\n",
    "        axs[0].plot(responseq2_plotting['nu'],responseq2_plotting[\"RL\"],color='black',label=\"RL Total Christy-Bodek Fit\", linestyle='dashed')    \n",
    "        axs[0].plot(responseq2_plotting['nu'],responseq2_plotting[\"RLQE\"],color='black',label=\"RL QE Christy-Bodek Fit\", linestyle='dotted')    \n",
    "        # axs[0].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RL_fortran_qvcenter_nu\"],label=\"Fortran RL\", s=3,color='black')    \n",
    "        axs[0].errorbar(fit['nu'], fit['RL'], yerr = fit['RLerr'], color='red', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[0].scatter(fit['nu'], fit['RL'],marker='D',s=6,color='red',label='RL this analysis')\n",
    "        axs[0].set_title(\"$Q^2=$\"+str(Q2center)+' bin:'+Q2bin_name)\n",
    "        axs[0].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[0].set_ylabel(\"$R_L$\")\n",
    "        # axs[0].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[0].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[0].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        # axs[0].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        axs[1].plot(responseq2_plotting['nu'],responseq2_plotting[\"RT\"],color='black',label=\"RT Total Christy-Bodek Fit\",linestyle='dashed')\n",
    "        axs[1].plot(responseq2_plotting['nu'],responseq2_plotting[\"RTQE\"],color='black',label=\"RT QE Christy-Bodek Fit\",linestyle='dotted')\n",
    "        # axs[1].scatter(responseq2_plotting['nu'],responseq2_plotting[\"RT_fortran_qvcenter_nu\"],label=\"Fortran RT\", s=3,color='black')\n",
    "        axs[1].errorbar(fit['nu'], fit['RT'], yerr = fit['RTerr'], color='red', fmt ='.',capsize=3,markersize='3')\n",
    "        axs[1].scatter(fit['nu'], fit['RT'],marker='D',s=6,color='red',label='RT this analysis')\n",
    "        axs[1].set_title(\"$Q^2=$\"+str(Q2center)+' bin:'+Q2bin_name)\n",
    "        axs[1].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[1].set_ylabel(\"$R_T$\")\n",
    "        # axs[1].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[1].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[1].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        # axs[1].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "\n",
    "        # photon-production data\n",
    "        if Q2center == 0.01:\n",
    "            axs[1].scatter(Photon_plotting['nu'],Photon_plotting[\"RT\"],marker='^',s=20,color='fuchsia',label=\"RT Photo-production ($Q^2=0$)\")\n",
    "            axs[1].plot(Photon_plotting['nu'],Photon_plotting[\"RT\"],color='black',lw=1)\n",
    "\n",
    "        if Q2center in Sheren_q2s:\n",
    "            Sheren = df_Sheren.loc[df_Sheren['Q2']==Q2center]\n",
    "            axs[0].errorbar(Sheren['nu'], Sheren['RL']*12, yerr = Sheren['RLerr']*12, color='royalblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[0].scatter(Sheren['nu'], Sheren['RL']*12,marker='D',s=6,color='royalblue',label=\"Sheren\")\n",
    "            axs[1].errorbar(Sheren['nu'], Sheren['RT']*12, yerr = Sheren['RTerr']*12, color='royalblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Sheren['nu'], Sheren['RT']*12,marker='D',s=6,color='royalblue',label=\"Sheren\")\n",
    "\n",
    "        Yam_RLmax = 0\n",
    "        Yam_RTmax = 0\n",
    "        if qvcenter in Yamaguchi_qvs:\n",
    "            Yam_data = pd.read_excel('Yamaguchi_plotting.xlsx',sheet_name='qv_'+str(qvcenter))\n",
    "            # Yam_data['nu_RL'] = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Yam_data['EX_RL'])\n",
    "            # Yam_data['nu_RT'] = - mass_C12 + np.sqrt(mass_C12**2 + qvcenter**2 + 2*mass_C12*Yam_data['EX_RT'])\n",
    "            # Ex = nu-(qv^2-nu^2)/(2M)\n",
    "            # nu = - M + sqrt(M^2 + qv^2 + 2M*Ex)\n",
    "            # solve quadratic equation\n",
    "            \n",
    "            # axs[0].errorbar(Yam_data['nu_RL'],Yam_data[\"RL\"], yerr = Yam_data[\"RL\"]*0.03, color='lightpink', fmt ='.',capsize=3,markersize='3')\n",
    "            # axs[0].scatter(Yam_data['nu_RL'],Yam_data[\"RL\"],marker='D',s=6,color='skyblue',label=\"RL Yamaguchi\")\n",
    "            axs[0].scatter(Yam_data['nu_RL'],Yam_data[\"RL\"],marker='D',s=6,color='cyan',label=\"RL Yamaguchi \"+'$\\mathbf{q}=$'+str(qvcenter))\n",
    "            axs[0].plot(Yam_data['nu_RL'],Yam_data[\"RL\"],lw=1,color='black')\n",
    "            # axs[1].errorbar(Yam_data['nu_RT'],Yam_data[\"RT\"], yerr = Yam_data[\"RT\"]*0.03, color='lightpink', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Yam_data['nu_RT'],Yam_data[\"RT\"],marker='D',s=6,color='cyan',label=\"RT Yamaguchi \"+'$\\mathbf{q}$='+str(qvcenter))\n",
    "            axs[1].plot(Yam_data['nu_RT'],Yam_data[\"RT\"],lw=1,color='black')\n",
    "            Yam_RLmax = Yam_data[\"RL\"].max()\n",
    "            Yam_RTmax = Yam_data[\"RT\"].max()\n",
    "            \n",
    "        # goldemberg\n",
    "        if qvcenter == 0.1: \n",
    "            Goldem_data = pd.read_csv('Goldemberger_180.csv')\n",
    "            axs[1].errorbar(Goldem_data['nu'],Goldem_data[\"RT\"], yerr = Goldem_data[\"error\"], color='skyblue', fmt ='.',capsize=3,markersize='3')\n",
    "            axs[1].scatter(Goldem_data['nu'],Goldem_data[\"RT\"],marker='D',s=6,color='blue',label=\"RT Goldemberg \"+'$\\mathbf{q}$='+str(qvcenter))\n",
    "        # # NuWRo\n",
    "        # if qvcenter in SF_FSI_qvs:\n",
    "        #     qvcenter_MeV = int(qvcenter*1000)\n",
    "        #     df_SF = pd.read_csv('SF_FSI/Resp_FSI_12C_'+str(qvcenter_MeV)+'_SF.txt',delim_whitespace=True,header=None)\n",
    "        #     df_SF.columns = ['nu','RL','RT']\n",
    "        #     axs[0].scatter(df_SF['nu']/1000,df_SF['RL'],label='RL QE NuWRo-SF-FSI',color='green',s=10)\n",
    "        #     axs[1].scatter(df_SF['nu']/1000,df_SF['RT'],label='RT QE NuWRo-SF-FSI',color='green',s=10)\n",
    "\n",
    "            \n",
    "\n",
    "        # W2_peaks = np.array([0.93,1.07,1.23])\n",
    "        W_peaks = np.array([0.93,1.07,1.23]) \n",
    "        W_colors = ['violet','forestgreen','royalblue']\n",
    "        W_height0 = fit['RL'].max()*1.3\n",
    "        W_height1 = fit['RT'].max()*1.3\n",
    "\n",
    "        # 0.8649, 1.1449, 1.5129\n",
    "        for i in range(len(W_peaks)):\n",
    "            # location = 0.025-mass_nucleon+np.sqrt(qvcenter**2+W_peaks[i]**2)\n",
    "            location = 0.025 + (W_peaks[i]**2+Q2center-mass_nucleon**2)/(2*mass_nucleon)\n",
    "            # if location < qvcenter:\n",
    "            axs[0].axvline(x=location, color = W_colors[i], linestyle='dashed')\n",
    "            axs[0].text(location, W_height0-i*0.08*W_height0 , '$W=$'+str(W_peaks[i]),color = 'black', ha = 'center')\n",
    "        \n",
    "            axs[1].axvline(x=location, color = W_colors[i], linestyle='dashed')\n",
    "            axs[1].text(location, W_height1-i*0.08*W_height1, '$W=$'+str(W_peaks[i]),color = 'black', ha = 'center')\n",
    "        \n",
    "        # axs[0].axvline(x=qvcenter, color = 'brown', linestyle='dashdot')\n",
    "        # axs[0].text(qvcenter, W_height0*0.9,  f'$\\\\nu={qvcenter}$'+'\\n$(Q^2=0)$' ,color = 'black',ha = 'center')\n",
    "\n",
    "        # axs[1].axvline(x=qvcenter, color = 'brown', linestyle='dashdot')\n",
    "        # axs[1].text(qvcenter, W_height1*0.9, f'$\\\\nu={qvcenter}$'+'\\n$(Q^2=0)$', color = 'black',ha = 'center')\n",
    "\n",
    "        axs[2].scatter(fit['nu'],fit['Chi2_DoF'],color='orange',s=10,label='$\\chi^2/DoF$')\n",
    "        axs[2].set_title('$\\chi^2/DoF$')\n",
    "        axs[2].set_xlabel(\"$\\\\nu(GeV)$\")\n",
    "        axs[2].set_ylabel(\"$\\chi^2/DoF$\")\n",
    "        # axs[2].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[2].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        # axs[2].tick_params(axis='both', direction='out',which='major',top=True,right=True)\n",
    "        # axs[2].tick_params(axis='both', direction='in',which='minor',top=True,right=True)\n",
    "        totalChi2 = np.sum(fit['Chi2'])\n",
    "\n",
    "\n",
    "        axs[0].set_xlim(0.0, fit['nu'].max()*1.1)\n",
    "        axs[1].set_xlim(0.0, fit['nu'].max()*1.1)\n",
    "        axs[2].set_xlim(0.0, fit['nu'].max()*1.1)\n",
    "        if Q2center == 0.01:\n",
    "            axs[0].set_xlim(0.0, 0.06)\n",
    "            axs[1].set_xlim(0.0, 0.06)\n",
    "            axs[2].set_xlim(0.0, 0.06)\n",
    "\n",
    "\n",
    "        axs0_y_low = 0\n",
    "        axs1_y_low = 0\n",
    "        if fit['RL'].min()<0:\n",
    "            axs0_y_low = fit['RL'].min()*1.05\n",
    "        if fit['RT'].min()<0:\n",
    "            axs1_y_low = fit['RT'].min()*1.05\n",
    "        if len(fit['nu']) > 0:\n",
    "            axs[0].set_ylim(axs0_y_low, W_height0*1.5)\n",
    "            axs[1].set_ylim(axs1_y_low, W_height1*1.5)\n",
    "\n",
    "\n",
    "\n",
    "        axs[0].legend()\n",
    "        axs[1].legend()\n",
    "        axs[2].legend()\n",
    "\n",
    "        plt.tight_layout()  # Optional, for better spacing between subplots\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/jscy9scn2vs_3w_p85mqhz_w0000gn/T/ipykernel_27632/456387166.py:2: DeprecationWarning: PdfMerger is deprecated and will be removed in pypdf 5.0.0. Use PdfWriter instead.\n",
      "  merger = PdfMerger()\n"
     ]
    }
   ],
   "source": [
    "# merge PDFs, Q2\n",
    "merger = PdfMerger()\n",
    "for Q2center in Q2centers:\n",
    "    merger.append('curve_fit/curve_fit_q2_'+str(Q2center)+'.pdf')\n",
    "# merger.write(\"RLRT_Q2bins.pdf\")\n",
    "merger.write('curve_fit_q2.pdf')\n",
    "merger.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 23 meeting\n",
    "'''\n",
    "-1. put W2 binding energy (in nu, its 0.025. convert to W2, put it on W peaks)\n",
    "-2. W peaks mark on top of the line, not legend\n",
    "-3. nu=qv legend: put (Q2=0)\n",
    "-4. Yamaguchi: connect dots with lines\n",
    "-5. Remove Ryan from plot\n",
    "-6. include Goldemberg in analysis\n",
    "7. Talk: why doing it: testing theory\n",
    "    1. define the regions (Q2=0.093) (use us and Yamaguchi)\n",
    "    2. compare to other data (use qv=0.3, 0.38, 0.57; Q2=0.16)\n",
    "        not comparing to NuWRo\n",
    "    3. Then show our data (W2<2.0) both Q2 and qv\n",
    "        comparing to NuWRo\n",
    "        Show our fit, our QE\n",
    "    4. our data only, fit, QE, \n",
    "        When Sheren involved, just use Sheren's data\n",
    "    5. compare to theory\n",
    "        GFMC, ED-RMF: available theory data: qv=0.3, 0.38, 0.57\n",
    "        take total data, subtract inelastic (delta-resonance, the peak on the right), to get QE only, so can compare with NuWRo\n",
    "-8. Make our data more visible (big points, sharp)\n",
    "-9. put on Sheren bin\n",
    "10. nuclear excitation, quasi-elastic, pion production, delta resonance\n",
    "    For bins with Yamaguchi data:\n",
    "    below Ex=30: Yamaguchi's avaible 40, we starts at 30 (all converted to nu)\n",
    "\n",
    "    for qv>30: no more yamaguchi, we use our data and our fit    \n",
    "    Ex \n",
    "-11: \n",
    "    nu<50: Ex bc analysis (then convert to nu)\n",
    "    nu>50: W2 bc analysis (then convert to nu)\n",
    "\n",
    "\n",
    "    \n",
    "Email Feb 21:\n",
    "-1.     I removed Q2=0.65 and Q2=1.05 bins and the corresponding q3=0.878 and 1.168 bins.   Now we should be very close to\n",
    "         what Sheren used.  The boundaries of Q2=0.5. and Q2=0.8,  and Q2=1.25 have changed to to absorb the bins that were removed. See attached\n",
    "\n",
    "-2.    Similarly the boundaries of  q3 = 0.756, 0.991 and 1.302 have also changed to absorb the bins that were removed.\n",
    "\n",
    "-3..   Can you apply a bin centering correction to q3=0.4 Barreau data to move it to q3=0.38. (on the plots show q=0.4->0.38)\n",
    "-4.     And Can you apply a bin centering correction to q3=0.55 Barreau data to move it to q3=0.57. (on the plots show q=0.55->0.57)\n",
    "\n",
    "-5.  On the Q2= 0.01, 0.020. 0.026  0.040. 0.045. 0.093. show the data from Goldberg and Yamaguchi for q=0.1, 0.148, 0.167, 0.205, 0.249, 0.307\n",
    "-6.  On the Q2=0.01 plot we should also show the Q2=0 plot for RT photo production.\n",
    "\n",
    "-5.  Both q3 and Q2 plots should be done vs. Ex bin centering and W^2 bin centering.  \n",
    "      Later we will convert Ex and W^2  to \\nu.   Then we will use the Ex data for Ex<0.05 GeV,   and use the W^2 data from Ex>0.05 GeV\n",
    "\n",
    "-6.  On the plots  Change “our fit”  “this analysis”\n",
    "\n",
    "-7.  Can you make the NuWRo Green dotted curve (Big dots) so that we can tell the difference between it and our QE plot\n",
    "\n",
    "-8.  The photoproduction data should be large RED symbol  (so it is different from everything else.)\n",
    "\n",
    "-9.  On the nuclear excitation region connect the blue points with a red line to show the peaks.\n",
    "\n",
    "8.  On q=0.24, q= 0.38 l q=0.649, q=0.992,   q=1.302.  1.691. 1.921l, 2.213,  2.783 plots the photoproduction data is not on the line\n",
    "\n",
    "9.  We need to finalize normalizations for  18. 29,  21\n",
    "\n",
    "10.   For the Ex and W^2 plots for q3. And for Q2,  can you run it so that we can see all the linear fits for RL and RT so\n",
    "        we can  look at normalizations and figure out which data are causing problems.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 26 notes\n",
    "'''\n",
    "-1. Regarding the one parameter fit. Please put the error from the two parameter fit also on RT.  \n",
    "     Plot publication quality\n",
    "     Current plots will be rejected by puclicaion\n",
    "\n",
    "-2. Our red points should be larger so they are clearly seen\n",
    "-3. All lines should be darker\n",
    "\n",
    "-4. All axis and legend should be much larger\n",
    "\n",
    "-5. Photo points much larger. \n",
    "\n",
    "6  need to get photo points on the correct nu=q line interpolate photon data to \n",
    "  Get it right\n",
    "-7. Spammer error double it \n",
    "-8. QE plot on RT   Change to QE+TE\n",
    "-9. Q^3 to bold q\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
